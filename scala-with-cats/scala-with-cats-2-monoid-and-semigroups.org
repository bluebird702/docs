#+STARTUP: showall
#+LATEX_CLASS: article
#+LATEX_CLASS_OPTIONS: [a4paper]
#+LATEX_HEADER: \usepackage{kotex}
#+LATEX_HEADER: \usepackage{CJKutf8}
#+LATEX_HEADER: \usepackage[utf8]{inputenc}
#+LATEX_HEADER: \usepackage{amsmath}
#+LATEX_HEADER: \usepackage[scale=0.75,twoside,bindingoffset=5mm]{geometry}
#+LATEX_HEADER: \usepackage[onehalfspacing]{setspace}
#+LATEX_HEADER: \usepackage{longtable}
#+AUTHOR: billy.angels
#+TITLE: Scala with Cats


* Introduction

Cats는 다양한 함수형 프로그래밍 도구들을 포함하고 있고, 개발자들이 원하는 도구를 선택해서 쓸 수 있도록 해준다. 이 도구들의 대부분은 이미 존재하는 Scala type에 적용이 가능한 type class의 형태로 제공된다.

Type class들은 Haskell에서 시작된 프로그래밍 패턴이다. Type class들은 이미 개발된 라이브러리들이 전통적으로 사용되는 상속이나, 기존 라이브러리 소스코드의 변경 없이 새로운 기능을 확장할 수 있게 해준다.

이 챕터에서는 Underscore의 Essential Scala 책에 있는 type class에 대해서 다시 한번 살펴보고 Cats codebase를 처음으로 살펴볼 것이다. 우리는 Show와 Eq, 두 개의 type class 예제를 통해서 이 책이 기본적으로 의지하는 패턴들을 식별할 것이다.

우리는 type class를 다시 Scala의 함수형 프로그래밍에 대한 구조적인 접근을 대표하는 algebric data type, pattern maching, value classes, type alias와 엮으면서 마무리할 것이다

** Anatomy of a Type Class

type class 패턴에서는 세가지 중요한 컴포넌트가 있다. 그것은 /type/ class 그 자체, 특정 type의 /instance/, 그리고 사용자에게 노출할 /interface/ method들이다.

*** The Type Class

/type class/ 는 우리가 구현하고자 하는 기능을 표현한 API 혹은 interface이다. Cats에서 type class는 최소한 하나의 type parameter를 가지는 trait으로 표현된다. 예를 들어, "JSON을 serialize한다"라는 generic한 행동을 다음과 같이 표현할 수 있다.

#+BEGIN_SRC scala
// Define a very simple JSON AST
sealed trait Json
final case class JsObject(get: Map[String, Json]) extends Json 
final case class JsString(get: String) extends Json
final case class JsNumber(get: Double) extends Json
case object JsNull extends Json

// The "serialize to JSON" behaviour is encoded in this trait
trait JsonWriter[A] {
  def write(value: A): Json
}
#+END_SRC

JsonWriter는 이 예제에서 Json과 그 subtype을 가진 우리의 type class이다. 

*** Type Class Instances

type class의 /instance/ 는 우리가 다루어야 하는 type을 위한 구현을 제공한다. 우리가 다루어야 하는 type은 Scala standara library의 type들과 우리의 도메인 모델에 있는 type을 포함한다.

Scala에서 우리는 type class의 concrete implementation을 만들고 이에 implicit keyword를 tag함으로써 instance를 정의한다.

#+BEGIN_SRC scala
final case class Person(name: String, email: String)

object JsonWriterInstances {
  implicit val stringWriter: JsonWriter[String] = 
    new JsonWriter[String] {
      def write(value: String): Json = JsString(value)
    }

  implicit val personWriter: JsonWriter[Person] = 
    new JsonWriter[Person] {
      def write(value: Person): Json = 
        JsObject(Map(
	  "name" -> JsString(value.name),
	  "email" -> JsString(value.email)
	))
    }
}
#+END_SRC

*** Type Class Interfaces

type class /interface/는 우리가 사용자들에게 노출하고 하는 기능이다. Interface들은 implicit parameter로 type class의 instance를 받을 수 있는 generic method들이다.

interface의 정의는 두가지 방법이 있다: /Interface Objects/와 /Interface Syntax/이다

*Interface Objects*
interface를 생성하는 가장 간단한 방법은 method를 singleton object에 두는 것이다. 

#+BEGIN_SRC scala
object Json {
  def toJson[A](value: A)(implicit w: JsonWriter[A]): Json =
    w.write(value)
}
#+END_SRC

이 object를 사용하기 위해서, 우리가 다루는 어떤 type class instance로든지 import해서 관련 method를 호출할 수 있다.

#+BEGIN_SRC scala
import JsonWriterInstances._
Json.toJson(Person("Dave", "dave@example.com"))
// res4: Json = JsObject(Map(name -> JsString(Dave), email -> JsString
     (dave@example.com)))
#+END_SRC

complier는 implicit parameter를 제공하지 않고 toJson method를 호출하는 지점을 잡아낸다. 그리고 compiler는 이를 고치기 위해서 관련 type의 type class instance를 찾고 이를 call하는 쪽에다가 집어넣는다

#+BEGIN_SRC scala
Json.toJson(Person("Dave", "dave@example.com"))(personWriter)
#+END_SRC

*Interface Syntax*
우리는 이미 interface method를 가지고 존재하는 type을 확장하기 위해서 /extension method/를 대신 사용할 수도 있다. Cats는 이를 type class를 위한 "/syntax/"라고 한다.

#+BEGIN_SRC scala
object JsonSyntax {
  implicit class JsonWriterOps[A](value: A) {
    def toJson(implicit w: JsonWriter[A]): Json =
      w.write(value)
} }
#+END_SRC 

우리는 우리가 필요로 하는 type의 instanced와 함께 importing하기 위해서 interface syntax를 사용한다.

#+BEGIN_SRC scala
import JsonWriterInstances._
import JsonSyntax._

Person("Dave", "dave@example.com").toJson
// res6: Json = JsObject(Map(name -> JsString(Dave), email -> JsString
     (dave@example.com)))
#+END_SRC

다시, compiler는 implicit parameter의 후보를 찾아서 집어넣어준다.

#+BEGIN_SRC scala
Person("Dave", "dave@example.com").toJson(personWriter)
#+END_SRC

The /*implicitly*/ Method

Scala standard library는 implicitly라고 하는 generic type class interface를 제공한다. implicitly의 정의는 매우 간단하다

#+BEGIN_SRC scala
 def implicitly[A](implicit value: A): A =
  value
#+END_SRC

우리는 implicitly를 사용해서 implicit scope에 있는 어떤 value라도 소환할 수 있다. 우리가 원하는 type을 제공하면 implicitly가 나머지는 알아서 한다.

#+BEGIN_SRC scala
import JsonWriterInstances._
// import JsonWriterInstances._
implicitly[JsonWriter[String]]
// res8: JsonWriter[String] = JsonWriterInstances$$anon$1@73eb1c7a
#+END_SRC

Cats에 있는 대부분의 type class들은 instance를 소환하기 위해 implicitly가 아닌 다른 방법으로 제공한다. 하지만 implicitly는 디버깅을 위해서는 좋은 fallback이다. 우리는 compiler가 type class의 instance를 찾는 걸 보장하기 위해서 우리 코드의 일반적인 흐름안에서 implicitly 호출을 추가함으로써 모호한 implicit error가 없는 걸 보장할 수 있다.

** Working with Implicits
Scala에서 type class로 작업한다는 것은 implicit value와 implicit parameter와 함께 작업한다는 것을 의미한다. 이를 효과적으로 하기 위해서는 알아야할 몇가지 규칙이 있다.

*** Packaging Implicits
언어의 별난점인데, Scala에서 implicit으로 설정된 어떤 정의도 최상단이 아니라 object나 trait 안쪽에 위치해야만 한다. 위의 예제에서, 우리는 JsonWriterInstances라는 object에 있는 type class instance를 패키징했다. 우리는 companion object에 있는 type class들을 JsonWriter에 똑같이 위치시킬 수 있다. companion object에 있는 instance들을 type class에 두는 것은 Scala에서 중요한 의미를 지니는데 그 이유는 /implicit scope/라고 불리는 무언가를 그안에 넣기 때문이다. 

*** Implicit Scope
우리가 위에서 봤듯이, compiler는 type에 의한 type class instance 후보들을 찾는다. 예를 들어, 다음의 expression에서 컴파일러는 JsonWriter[String] type의 instance를 찾을 것이다.

#+BEGIN_SRC scala
Json.toJson("A string!")
#+END_SRC

compiler는 호출하는 부분의 implicit scope에 있는 후보 instance들을 찾는다.

- local or inherited definitions;
- import된 defitions;
- type class 혹은 parameter type(이 경우에는 JsonWriter 혹은 String)의 companion object에 있는 definition

Definition들은 만약 implicit keyword에 tag되면 implicit scope에만 포함된다. 그러므로, 만약 compiler가 여러개의 후보 definition을 본다면, compiler는 /ambigous implicit values/ error와 같이 실패할 것이다.

#+BEGIN_SRC scala
implicit val writer1: JsonWriter[String] =
  JsonWriterInstances.stringWriter

implicit val writer2: JsonWriter[String] =
  JsonWriterInstances.stringWriter

Json.toJson("A string")
// <console>:23: error: ambiguous implicit values:
// both value stringWriter in object JsonWriterInstances of type =>
     JsonWriter[String]
//  and value writer1 of type => JsonWriter[String]
// match expected type JsonWriter[String] // Json.toJson("A string")
//
#+END_SRC

implicit resolution의 간결한 규칙은 이것보다 더 복잡하지만, 이러한 복잡성은 이 책과는 크게 연관이 없다. 우리의 목적을 위해서, 우리는 네가지 방법으로 type class instance를 패키징할 수 있다.

- JsonWriterInstances와 같은 object에 type class를 위치시킨다
- trait에 type class를 위치시킨다
- type class의 companion에 type class를 위치시킨다
- parameter type의 companion object를 위치시킨다

option 1에서 우리는 type class를 import함으로써 instance를 scope에 포함시킨다.option 2는 상속의 scope로 type class를 가져온다. option 3과 option 4에서, 우리가 쓰던 안쓰던 instance는 항상 implicit scope에 있다 

*** Recursive Implicit Resolution

type class와 implicit의 힘은 후보 instance들 찾을 때 implicit definition을 조합하는 컴파일러의 능력에 의존한다.

모든 type class instance들은 implicit vals이다. 이것은 간단하다. 우리는 두가지 방법으로 instance를 정의할 수 있다.

- 요구되는 type을 implicit vals로서 concreate instance들을 정의해서
- 다른 type class instance로부터 instance를 만드는 implicit method를 정의해서

왜 우리는 다른 instance로부터 instance를 만들어낼까? Options를 위한 JsonWriter를 정의하는 것을 고려해보자. 우리는 애플리케이션에서 다루어야 하는 모든 A를 위한 JsonWriter[Option[A]]가 필요하다. 우리는 implicit vals의 라이브러리를 생성함으로써 문제를 하나하나 모두 시도해볼수도 있다.

#+BEGIN_SRC scala
implicit val optionIntWriter: JsonWriter[Option[Int]] = ???
implicit val optionPersonWriter: JsonWriter[Option[Person]] = ???
// and so on...
#+END_SRC
 
하지만, 이 접근은 확실하게 확장을 하기가 어렵다. 우리는 애플리케이션의 모든 A type을 위한 두 개 의 implicit vals를 필요로 한다: 하나는 A를 위한 것과 하나는 Option[A]를 위한것이다.

운 좋게도, 우리는 Option[A]를 다루는 code를 A를 위한 instance에 기반한 공통의 생성자로 추상화할 수 있다.

- 만약 option이 Some(aValue)라면, A를 위한 writer를 사용해서 aValue를 쓴다
- 만약 option이 None이라면, null을 쓴다

여기 implicit def로 작성한 같은 코드가 있다

#+BEGIN_SRC scala
implicit def optionWriter[A]
(implicit writer: JsonWriter[A]): JsonWriter[Option[A]] =
  new JsonWriter[Option[A]] {
    def write(option: Option[A]): Json =
      option match {
        case Some(aValue) => writer.write(aValue)
        case None         => JsNull
} }
#+END_SRC

이 메소드는 A-specific 기능을 채우기 위한 implicit parameter에 의존한 Option[A]를 위한 JsonWriter를 만들어낸다. compiler가 보는 expression은 다음과 같다

#+BEGIN_SRC scala
Json.toJson(Option("A string"))
#+END_SRC

copiler는 implicit JsonWriter[Option[String]]을 찾는다. 그리고 JsonWriter[Option[A]]를 위한 implicit method를 찾게 된다.

#+BEGIN_SRC scala
Json.toJson(Option("A string"))(optionWriter[String])
#+END_SRC

그리고 recursive하게 optionWriter의 parameter로 사용하기 위해서 JsonWriter[String]를 찾아낸다

#+BEGIN_SRC scala
Json.toJson(Option("A string"))(optionWriter(stringWriter))
#+END_SRC

이러한 경우, implicit resolution은 정확한 모든 type의 type class을 소환하는 조합을 찾기 위해서 implicit definition의 가능한 조합을 모두 찾게 된다

#+BEGIN_SRC 
Implicit Conversions

implicit def를 사용하는 type class instance constructor를 생성할 때, implicit parameters로서 parameter를 method에 전달하는 것을 보장해야 한다. 이 keyword가 없다면, compiler는 implicit 처리 시에 parameter들을 채울 수 없을 것이다.

non-implicit parameter와 같이 있는 implicit method는 implicit conversion이라고 불리는 다른 scala pattern을 만들어낸다. implicit conversion은 현대의 scala code에서 얼굴을 찌푸리게 하는 오래된 programming pattern이다. 운 좋게도, compiler는 이렇게 사용하려고 하면 경고할 것이다. scala.language.implicitConversions를 import하면 implicit conversion을 수동으로 사용가능하게 할 수 있다.

#+END_SRC

#+BEGIN_SRC scala
implicit def optionWriter[A]
(writer: JsonWriter[A]): JsonWriter[Option[A]] =
???
// <console>:18: warning: implicit conversion method optionWriter should be enabled
// by making the implicit value scala.language.
     implicitConversions visible.
// This can be achieved by adding the import clause 'import scala.language.implicitConversions'
// or by setting the compiler option -language:
     implicitConversions.
// See the Scaladoc for value scala.language.implicitConversions for a discussion
// why the feature should be explicitly enabled.
// // //
       implicit def optionWriter[A]
                    ^
error: No warnings can be incurred under -Xfatal-warnings.
#+END_SRC


** Exercise: Printable Library

생략

** Meet Cats
이전 섹션에서 Scala에서 어떻게 type class를 구현하는지 봤다. 이 섹션에서는 Cats에서 어떻게 type class를 구현하는지 볼 것이다. 

Cats는 우리가 원하는 대로 사용할 수 있는 어떤 type class, instance, interface method든 선택할 수 있게 해주는 modular 구조를 사용해서 작성되었다. 첫번째로 cats.Show를 사용한 예제를 살펴보자

Show는 이전 섹션에서 정의한 Printable type class의 Cats 버전이다. Show는 toString을 사용하지 않고 개발자 친화적인 console output을 위한 매커니즘을 제공한다. 다음은 생략된 definition이다

#+BEGIN_SRC scala
package cats

trait Show[A] {
  def show(value: A): String
}
#+END_SRC

*** Importing Type Classes
Cats에서 type class들은 cats package에 정의된다. 이 패키지로부터 바로 Show를 import할 수 있다

#+BEGIN_SRC scala
import cats.Show
#+END_SRC

모든 Cats의 companion object는 우리가 정의하는 어떤 type의 instance도 가지고 있는 apply method를 가지고 있다:
#+BEGIN_SRC scala
val showInt = Show.apply[Int]
// <console>:13: error: could not find implicit value for parameter
instance: cats.Show[Int]
// val showInt = Show.apply[Int] //
#+END_SRC

Oops - 동작하지 않는군요! apply method는 각각의 instance들을 찾기 위해 /implicit/을 사용한다. 그래서 몇몇 instance들을 scope로 가져올 것이다

*** Importing Default Instances
cats.instances package는 넓은 범위의 type을 위해 default instance를 제공한다. 다음의 table에서 보여지는 것들을 import할 수 있다. 각 import는 특정 parameter type을 위한 모든 Cats't type class들의 instance를 제공한다

- cats.instances.int는 Int를 위한 instance를 제공한다.
- cats.instances.string는 String을 위한 instance를 제공한다.
- cats.instances.list는 List를 위한 instance를 제공한다
- cats.instances.option은 Option을 위한 instance를 제공한다.
- cats.instances.all은 Cats와 함께 포함된 모든 instance를 제공한다.

cats.instances package는 가능한 import의 완벽한 목록을 참고해라

Int와 String을 위한 Show의 instance를 import해보자

#+BEGIN_SRC scala
import cats.instances.int._    // for Show
import cats.instances.string._ // for Show

val showInt: Show[Int] = Show.apply[Int] 
val showString: Show[String] = Show.apply[String]
#+END_SRC

더 나아진 것 같다! Show의 두 instance에 접근할 수 있으며 Ints와 Strings를 출력하기 위해서 이들을 사용할 수 있다:

#+BEGIN_SRC scala
val intAsString: String =
  showInt.show(123)
// intAsString: String = 123
val stringAsString: String =
  showString.show("abc")
// stringAsString: String = abc
#+END_SRC

*** Importing Interface Syntax
우리는 cats.syntax.show로부터 interface syntax를 import해서 Show를 더 편하게 사용할 수 있도록 할 수 있다. cats.syntax.show는 모든 타입을 위한 show라고 불리는 extension method를 추가한다

#+BEGIN_SRC scala
import cats.syntax.show._ // for show
val shownInt = 123.show
// shownInt: String = 123
val shownString = "abc".show
// shownString: String = abc
#+END_SRC 

Cats는 각 type class를 위한 분리된 syntax import를 제공한다. 이후에 섹션과 챕터에서 이러한 것들을 소개하겠다.

*** Importing All The Things!
이 책에서 우리는 각 예제에서 필요로 하는 instance와 syntax를 정확히 보여주기 위해서 정확한 import를 사용할 것이다. 하지만, 이런 방식은 많은 경우 시간이 들 수 있다. import를 간단하게 하기 위한 다음의 shortcut 중 하나를 편하게 사용해도 된다.

- import cats._는 Cats의 type class를 모두 import한다.
- import cats.instance.all._는 standard library르 위한 type class instance 모두를 import한다
- import cats.syntax.all._는 syntax 모두를 import한다
- import cats.implicits._는 모든 syntax와 standard type class instance 모두를 import한다

대부분의 사람들이 다음의 import로 파일을 시작한다. 이 import는 이름 충돌이나 모호한 implicit 문제가 있을 때에만 더 구체적인 import로 돌릴 수 있다. 

#+BEGIN_SRC scala
import cats._
import cats.implicits._
#+END_SRC 

*** Defining Custom Instances
주어진 type을 위한 trait을 구현하는 것에 의해서 간단히 Show의 instance를 정의할 수 있다.

#+BEGIN_SRC scala
import java.util.Date
implicit val dateShow: Show[Date] =
  new Show[Date] {
    def show(date: Date): String =
      s"${date.getTime}ms since the epoch."
}
#+END_SRC

하지만, Cats는 프로세스를 간단하게 하는 편리한 method들을 제공한다. 자체적인 type을 위한 instance를 정의하기 위해서 사용하는 Show의 companion object에 있는 두가지 construction method가 있다. 

#+BEGIN_SRC scala
object Show {
  // Convert a function to a `Show` instance:
  def show[A](f: A => String): Show[A] =
  ???
  // Create a `Show` instance from a `toString` method:
  def fromToString[A]: Show[A] =
  ???
}
#+END_SRC

이러한 것들은 바닥부터 이를 정의하는 것보다 훨씬 더 적은 노력으로 빠르게 instance를 생성할 수 있도록 한다.

#+BEGIN_SRC scala
implicit val dateShow: Show[Date] =
Show.show(date => s"${date.getTime}ms since the epoch.")
#+END_SRC

보다시피, construction method를 사용하는 code는 code가 거의 없을 정도록 훨씬 간결하다. Cats에 있는 많은 type class는 instance를 생성할 수 있는 이런 helper method를 제공하며 이 method들은 바닥부터 하거나 혹은 이미 존재하는 instance를 다른 type으로 transform할 수 있게 한다.

*** Exercise: Cat Show
생략

** Example: Eq
또다른 유용한 type class를 살펴보고 이 챕터를 마무리하겠다. 바로 cats.Eq이다. Eq는 type-safe equality를 지원하고 Scala의 built-in == 연산자를 사용할 때 짜증나는 부분에 집중한다. 

대부분 모든 Scala 개발자는 이전에는 다음과 같이 코드를 작성했다.

#+BEGIN_SRC scala
 List(1, 2, 3).map(Option(_)).filter(item => item == 1)
// res0: List[Option[Int]] = List()
#+END_SRC

좋다, 많은 사람들은 다음과 같은 실수를 하지 않을 수 있지만, 그 원칙은 타당하다. filter clause의 predicate는 항상 false를 리턴한다. 왜냐하면 Int와 Option[Int]를 비교하기 때문이다.

이것은 프로그래머 에러이다 - item을 1 대신에 Some(1)과 비교해야만 한다. 하지만, 이건 기술적으로 type error가 아니다. 왜냐하면 ==는 우리가 비교하는 어떤 type이든 어떤 객체와든 동작해야 하기 때문이다. Eq는 equality check와 이 문제를 잘 동작하게 하기 위해서 몇가지 type safety를 추가하기 위해 설계되었다.

*** Equality, Liberty, and Fraternity
우리는 Eq를 모든 주어진 type간의 type-safe equality를 정의하기 위해서 사용할 수 있다.

#+BEGIN_SRC scala
package cats
trait Eq[A] {
  def eqv(a: A, b: A): Boolean
  // other concrete methods based on eqv...
}
#+END_SRC

cats.syntax.eq에 정의된 interface syntax는 해당 scope에 있는 Eq[A] instance의 quality check를 위한 두가지 method를 제공한다.

- ===는 두 개의 object를 비교한다
- =!=는 두 개의 object가 다른지를 비교한다

*** Comparing Ints
몇가지 예를 살펴보자. 우선 type class를 import해보자

#+BEGIN_SRC scala
import cats.Eq
#+END_SRC

이제 Int인 instance를 설정해보자

#+BEGIN_SRC scala
import cats.instances.int._ // for Eq

val eqInt = Eq[Int]
#+END_SRC

이제 eqInt를 이용해서 바로 equality를 테스트할 수 있다.

#+BEGIN_SRC scala
eqInt.eqv(123, 123)
// res2: Boolean = true
eqInt.eqv(123, 234)
// res3: Boolean = false
#+END_SRC

Scala의 == method와 다르게, 만약 eqv를 사용해서 서로 다른 type의 object를 비교하려고 하면 compile error를 보게 된다

#+BEGIN_SRC scala
eqInt.eqv(123, "234")
// <console>:18: error: type mismatch; // found : String("234")
// required: Int
// eqInt.eqv(123, "234")
//
#+END_SRC

또한 ===와 =!= method를 사용하기 위해 cats.syntax.eq에 있는 interface syntax를 import해보자

#+BEGIN_SRC scala
import cats.syntax.eq._ // for === and =!=

123 === 123
// res5: Boolean = true
123 =!= 234
// res6: Boolean = true
#+END_SRC

다시, 서로 다른 type의 값을 비교하면 compile error가 발생한다

*** Comparing Options
자..이제 더욱 재미있는 예제르 살펴보자. 바로 Option[Int]이다. Option[Int]인 type의 값을 비교하기 위해서 우리는 Int뿐만 아니라 Option을 위한 Eq의 instance도 import해보자

Int:
#+BEGIN_SRC scala
import cats.instances.int._    // for Eq
import cats.instances.option._ // for Eq
#+END_SRC

이제 몇가지 비교를 해보자

#+BEGIN_SRC scala
Some(1) === None
// <console>:26: error: value === is not a member of Some[Int] // Some(1) === None
//
#+END_SRC

type이 맞지 않기 때문에 error를 받았다. Int와 Option[Int]의 Eq instance들이 있지만, 비교하는 값들은 Some[Int] type의 값이다. 이 문제를 해결하기 위해서 Option[Int]로서의 argument를 다시 작성해야 한다

#+BEGIN_SRC scala
(Some(1) : Option[Int]) === (None : Option[Int])
// res9: Boolean = false
#+END_SRC

standard library에 있는 Option.apply와 Option.empty를 이용해서 좀 더 친숙한 방식으로 할 수 있다

#+BEGIN_SRC scala
Option(1) === Option.empty[Int]
// res10: Boolean = false
#+END_SRC

혹은 cats.syntax.option에 있는 특별한 syntax를 사용할 수도 있다

#+BEGIN_SRC scala
import cats.syntax.option._ // for some and none
1.some === none[Int]
// res11: Boolean = false
1.some =!= none[Int]
// res12: Boolean = true
#+END_SRC

*** Comparing Custom Types
Eq를 이용해서 Eq의 instance를 정의할수도 있다. (A,A) => Boolean type의 함수를 받아서 Eq[A]를 리턴하는 걸 정의해보자:

#+BEGIN_SRC scala
import java.util.Date
import cats.instances.long._ // for Eq

implicit val dateEq: Eq[Date] =
  Eq.instance[Date] { (date1, date2) =>
    date1.getTime === date2.getTime
  }

val x = new Date() // now
val y = new Date() // a bit later than now

x === x
// res13: Boolean = true

x === y
// res14: Boolean = false
#+END_SRC

*** Exercise: Equality, Liberty, and Felinity
생략

** Controlling Instance Selection
type class를 사용할 때에는 instance를 선택하는 데 있어 두가지 이슈를 고려해야만 한다

- type에 정의된 instance와 subtype간의 관계는 어떻게 되는가?
예를 들어 만약 우리가 JsonWriter[Option[Int]]를 정의했다면, Json.toJson(Some(1))은 이 instance를 선택할 것인가(Some은 Option의 subtype이라는 것을 기억하자)
- 많은 type class instance들이 있을 때 어떻게 선택할 것인가?
만약 Person을 위한 JsonWriter가 두개라면? Json.toJson(aPerson)이라는 코드는 어떤 instance를 선택할 것인가??

*** Variance
type class를 정의할 때에는, implicit을 찾는 동안 instance를 선택하게 하기 위해 type class의 variance와 compiler의 능력의 영향을 미치는 type parameter에 variance annotation을 추가할 수 있다. 

Essential Scala를 다시 돌아보면, variance는 subtype과 관련되어 있다. 만약 type A의 값이 기대되는 어떤 곳에도 type B의 값을 사용할 수 있다면 B는 A의 subtype이라고 할 수 있다.

Co-와 contravariance annotation은 type constructor와 함께 동작할 때 발생한다. 예를 들어, covariance는 + 기호와 함께 표시할 수 있다.

#+BEGIN_SRC scala
trait F[+A] // the "+" means "covariant"
#+END_SRC

*Covariance*
Covariance는 B가 A의 subtype이면 F[B]는 F[A] type의 subtype을 의미한다. 이는 List와 Option과 같은 collection을 포함한 많은 type을 모델링할 때 유용하다:

#+BEGIN_SRC scala
trait List[+A]
trait Option[+A]
#+END_SRC

Scala collection의 covariance는 하나의 type으로 구성된 collection에서 다른 type의 collection으로 교체할 수 있게 한다. 예를 들어, Circle은 Shape의 subtyp이기 때문에 List[Shape]가 들어가야하는 어떤 곳에도 List[Circle]을 사용할 수 있다.

#+BEGIN_SRC scala
sealed trait Shape
case class Circle(radius: Double) extends Shape

val circles: List[Circle] = ???
val shapes: List[Shape] = circles
#+END_SRC

contravariance는 어떤가? 다음과 같이 -기호를 가진 type constructor로 contrvariant를 작성할 수 있다.

#+BEGIN_SRC scala
trait F[-A]
#+END_SRC

*Contravariance*
혼란스럽게도, contravariance는 만약 A가 B의 subtype이면 F[B]가 F[A]의 subtype이라는 것을 의미한다. contravariance는 위에서 언급한 JsonWriter type class같은 프로세스를 표현하는 type을 모델링하기에 유용하다:

#+BEGIN_SRC scala
trait JsonWriter[-A] {
  def write(value: A): Json
}
// defined trait JsonWriter
#+END_SRC

좀 더 풀어보자. variance는 하나의 값을 다른 값으로 변환하는 것에 대한 것이라는 것을 기억하자.  Shape type과 Circle type 두 가지 값과 Shape와 Circla을 위한 두개의 JsonWirter를 가지는 시나리오를 고려하자:

#+BEGIN_SRC scala
val shape: Shape = ???
val circle: Circle = ???

val shapeWriter: JsonWriter[Shape] = ???
val circleWriter: JsonWriter[Circle] = ???

def format[A](value: A, writer: JsonWriter[A]): Json = writer.write(value)
#+END_SRC

이제 스스로에게 물어보자: "format에 어떤 값과 JsonWriter의 조합을 보낼것인가?" 우리는 둘 중 어떤 writer든지 circle과 조합할 수 있다. 왜냐하면 모든 Circle은 Shape이기 때문이다. 반대로, 모든 Shape들은 Circle이 아니기 떄문에 shape와 circleWriter는 조합할 수 없다.

이 관계가 contravariance를 사용해서 모델링한 것이다. JsonWriter[Shape]는 JsonWriter[Circle]의 subtype이다. 왜냐하면 Circle이 Shape의 subtype이기 때문이다. 이는 JsonWriter[Circle]을 볼수 있으면 하는 모든 곳에서 shapeWriter를 쓸 수 있다는 것을 의미한다.
 
*Invariance*
Invariance는 설명하기에는 가장 간단한 내용이다. 요건 우리가 +나 -를 type constructor에 사용하지 않을 때 얻을 수 있는 것을 말한다.

#+BEGIN_SRC scala
trait F[A]
#+END_SRC

이 코드의 의미는 F[A]와 F[B]가 A와 B의 관계가 어떻든 간에 서로 간에 전혀 subtype이 형성되지 않음을 의미한다. 이는 Scala type constructor를 위한 기본적인 의미이다.

compiler는 implicit을 찾을 때 매칭되는 type이나 subtype을 찾는다. 그래서 몇몇 확장으로 type class instance를 제어하기 위해서 variance annotation을 사용할 수 있다.

여기서 발생하는 두가지 issue가 있다. 다음과 같은 algebraic data type이 있다고 생각해보자.

#+BEGIN_SRC scala
sealed trait A
final case object B extends A
final case object C extends A
#+END_SRC

이슈는 다음과 같다 

1. 만약 가능하다면 선택된 supertype에 정의된 instance가 선택될 수 있는가? 예를 들어, A의 instance를 정의하고 B와 C type의 값으로 사용이 가능한가?

2. supertype의 subtype을 위한 instance가 선택될 수 있는가?

한번에 두가지를 다 할수는 없다. 우리가 할 수 있는 행동은 다음의 세가지 선택지이다.

완벽한 시스템이 없다는 건 확실하다. Cats는 일반적으로 invariant type class를 사용하는 것을 선호한다. 이는 원한다면 subtype을 위한 더 자세한 instance를 정의할 수 있도록 한다는 것을 의미한다. 우리가 만약 Some[Int] type의 값을 가지고 있다면 Option을 위한 type class instance는 사용되지 않을 것이라는 것을 의미한다. 이 문제를 해결하기 위해서 Some(1) : Option[Int] 같은 type annotation을 사용하거나 Option.apply, Option.empty, some, none method같은 "smart constructor"를 사용할 수 있고 이는 Section 1.5.3에서 살펴봤다

** Summary
이 챕터에서는 type class를 처음 살펴보았다. Cats의 Show와 Eq를 이용한 두가지 예제를 살펴보기 전에 plain Scala를 사용한 Printable type class를 구현해봤다.

우리는 Cats type class에 있는 일반적인 패턴을 보아왔다.
- type class자체는 cats package에 있는 generic trait이다.
- 각 type class는 instance를 materialize할 수 있는 apply method를 가지고 있는 companion object를 가지고 있다. apply method는 instance를 만들기 위한 하나 혹은 그 이상의 /constructor/와 관련된 helper method들을 가지고 있다. 
- Default instance들은 cats.instances 패키지에서 object를 통해서 제공되고 type class에서 보다 parameter type에 의해서 구성된다.
- 많은 type class들은 cats.syntax package를 통해 제공되는 /syntax/를 가진다.

Part 1의 남은 챕터에서는 몇몇 폭넓고 강력한 type class를 살펴볼 것이다 - Semigroup, Monoid, Functor, Semigroupal, Applicative, Traverse 등등이다. 각각의 경우에 대해서 우리는 type class가 제공하는 기능과 따르고 있는 규칙들과 어떻게 Cats에 구현되어 있는 지를 배울 것이다. 이 type class들 중에 많은 부분은 Show나 Eq보다 더 추상화되어 있다. 이러한 부분이 배우기 더 어렵게 하기도 하지만 우리의 코드에 있는 일반적인 문제들을 푸는데 훨씬 더 유용하게 해준다.


* Monoids and Semigroups
이 장에서는 첫번째 type class인 monoid와 semigroup을 살펴볼 것이다. 이 두가지 type class는 값을 추가하거나 합칠 수 있도록 해준다. Ints, String, Lists, Options 등을 많은 instance들이 있다. 추출할 수 있는 공통의 원칙을 볼 수 있는 몇가지 간단한 type과 operation을 살펴보자

*Integer addition*
Ints의 더하기는 닫힌 binary operations이다(닫힌이라는 뜻은 두개의 Ints를 더해도 항상 또다른 Int를 생성한다는 것을 의미한다.)

#+BEGIN_SRC scala
2 + 1
// res0: Int = 3
#+END_SRC

또한 어떤 Int값에 대해서 a + 0 == 0 +a a == a인 identity element 0의 값이 존재한다. 

#+BEGIN_SRC scala
2 + 0
// res1: Int = 2
0 + 2
// res2: Int = 2
#+END_SRC

더하기에는 또다른 속성이 존재한다. 예를 들어서 어떤 순서로든지 element를 더할 수 있다. 왜냐하면 항상 동일한 결과를 얻을 수 있기 때문이다. 이를 associativity라고 한다.

#+BEGIN_SRC scala
(1 + 2) + 3
// res3: Int = 6
1 + (2 + 3)
// res4: Int = 6
#+END_SRC 

*Integer multiplication*
더하기의 속성들은 또한 곱하기에도 적용가능하다. identity value로 1을 사용하면 말이다

#+BEGIN_SRC scala
1*3
// res5: Int = 3
3*1
// res6: Int = 3
#+END_SRC

더하기와 마찬가지로 곱하기도 associative하다.

#+BEGIN_SRC scala
(1 * 2) * 3
// res7: Int = 6
1 * (2 * 3)
// res8: Int = 6
#+END_SRC

*String and sequence concatenation*
Strings도 binary operator로 concatenation해서 더할 수 있다

#+BEGIN_SRC scala
 "One" ++ "two"
// res9: String = Onetwo
#+END_SRC

identity value로는 empty string을 사용하면 된다

#+BEGIN_SRC scala
"" ++ "Hello"
// res10: String = Hello
"Hello" ++ ""
// res11: String = Hello
#+END_SRC

또한 concatenation은 associative하다
#+BEGIN_SRC scala
("One" ++ "Two") ++ "Three"
// res12: String = OneTwoThree

"One" ++ ("Two" ++ "Three")
// res13: String = OneTwoThree
#+END_SRC

sequence와 함께 병렬처리를 할 수 있기 위해서 더 일반적인 +보다 ++를 사용한 것을 기억하자. binary operator로서 concatenation과 identity로서 빈 sequence를 사용하여 다른 type의 sequence도 같은 방식으로 할 수 있다.

** Definition of a Monoid
위에서 각각의 associative binary addition과 identity element를 가지는 더하기 시나리오들을 봤다. 이것이 monoid이다. type A를 위한 monoid는 다음의 규칙을 만족한다

- type (A, A) => A를 하는 combine operation
- type A의 element empty

이 정의는 훌륭하게 Scala code로 만들어낼 수 있다. 다음은 Cats에 있는 아주 간단한 버전의 Monoid정의이다.

#+BEGIN_SRC scala
trait Monoid[A] {
  def combine(x: A, y: A): A
  def empty: A
}
#+END_SRC

combine과 empty operatio을 제공하는 것에 추가로, monoid는 몇가지 법칙을 따라야만 한다. A type인 모든 값 x,y,z에 대해서 combine은 associative하고 empty는 identity element여야 한다.

#+BEGIN_SRC scala
def associativeLaw[A](x: A, y: A, z: A)
      (implicit m: Monoid[A]): Boolean = {
  m.combine(x, m.combine(y, z)) ==
    m.combine(m.combine(x, y), z)
}
def identityLaw[A](x: A)
      (implicit m: Monoid[A]): Boolean = {
  (m.combine(x, m.empty) == x) &&
    (m.combine(m.empty, x) == x)
}
#+END_SRC
Integer 빼기는 Monoid가 아니다. 왜냐하면 빼기는 associative하지 않기 때문이다.

#+BEGIN_SRC scala
(1 - 2) - 3
// res15: Int = -4
1 - (2 - 3)
// res16: Int = 2
#+END_SRC

실제로 Monoid instance를 작성할 때에는 해당 규칙들에 대해서만 생각하면 된다. 규칙을 어긴 instance들은 Cats 내의 다른 부분에서 사용될 때 의도치 않은 결과를 낼 수 있기 때문이다. 대부분의 경우 Cats가 제공하는 instance에 의지할 수 있고 library 개발자들은 개발자들 스스로 무슨 일을 하는 지 알고 있다고 가정한다. 

** Definition of a Semigroup
semigroup은 monoid의 combine 부분만을 말한다. 많은 semigroup들은 monoid이지만, empty를 정의할 수 없는 몇몇 data type들이 있다. 예를 들면 sequence concatenation과 integer addition은 monoid라는 걸 이미 살펴봤다. 하지만 만약 우리가 non-empty sequence와 positive integer만으로 제한한다면 더 이상 empty element를 정의할 수 없다. Cats는 Semigroup의 구현이 있지만 Monoid의 구현은 아닌 NonEmptyList data type을 가지고 있다.

Cats의 Monoid의 더욱 정확한 의미는 다음과 같다
#+BEGIN_SRC scala
trait Semigroup[A] {
  def combine(x: A, y: A): A
}
trait Monoid[A] extends Semigroup[A] {
  def empty: A
}
#+END_SRC

type class에 대해서 논의 할 때 이러한 상속의 종류에 대해서 살펴볼 것이다. 상속은 modularity를 제공하고 재사용할 수 있도록 해준다. 만약 type A에 대한 Monoid를 정의한다면 Semigroup은 공짜로 얻게 된다. 이와 유사하게, 만약 method가 Semigroup[B]의 type의 parameter를 필요로 한다면, 우리는 Monoid[B]를 대신 넘길 수 있다.
 
** Exercise: The Truth About Monoids
monoid를 위한 몇가지 예제를 살펴보긴 했지만 이에 대한 예제는 훨씬 더 많다. Boolean을 생각해보자. 이 type에 대해 얼마나 많은 Monoid를 정의할 수 있을까?? 각각의 monoid는 combine과 empty operation을 정의하고 스스로 monoid 규칙을 만족시켰다는 걸 납득하자. 시작할 때에는 다음의 정의를 사용하자.

#+BEGIN_SRC scala
trait Semigroup[A] {
  def combine(x: A, y: A): A
}
trait Monoid[A] extends Semigroup[A] {
  def empty: A
}
object Monoid {
  def apply[A](implicit monoid: Monoid[A]) =
    monoid 
}
#+END_SRC

** Exercise: All Set for Monoids
** Monoids in Cats
이제 monoid가 무엇인지에 대해서 보았으니, Cats에서는 어떻게 구현했는지 살펴보자. 다시 한번 구현의 세가지 요소를 살펴보자: /type/ class, the /instance/, and the /interface/

*** The Monoid Type Class
monoid type class는 cats.kernel.Monoid이다. 이 클래스는 cats.Monoid로 alias되어 있다. Monoid는 cats.Semigroup으로 alias된 cats.kernel.Semigroup을 상속한다. Cats를 사용할 때에는 보통 cats package에 있는 type class를 import한다

#+BEGIN_SRC scala
import cats.Monoid
import cats.Semigroup
#+END_SRC

Cats Kernel?

Cats Kernel은 전체 Cats toolbox를 필요로 하지 않는 library를 위한 작은 typeclass의 집합을 제공하는 Cats의 subproject이다. 이 core type class들은 기술적으로 cats.kernel package에 정의되어 있지만, 모두 cats package로 alias되어 있어서 구별을 거의 할 수 없다. 

이 책에서 다루는 Cats Kernel type class들은 Eq, Semigroup, Monoid이다. 다른 type class들은 main Cats project의 부분이고 그대로 cats package에 정의되어 있다.

*** Monoid Instances
Monoid는 user interface를 위한 standard Cats pattern을 따른다: companion object는 특정 type을 위한 type class instance를 리턴하는 apply method를 가진다. 예를 들어, 만약 String을 위한 monoid instance를 원한다면 정확한 implicit을 scope에 넣어야 한다. 그러면 다음과 같이 작성할 수 있다

#+BEGIN_SRC scala
import cats.Monoid
import cats.instances.string._ // for Monoid

Monoid[String].combine("Hi ", "there")
// res0: String = Hi there

Monoid[String].empty
// res1: String = ""
#+END_SRC

#+BEGIN_SRC scala
Monoid.apply[String].combine("Hi ", "there") // res2: String = Hi there

Monoid.apply[String].empty
// res3: String = ""
#+END_SRC

이미 알고 있듯이, Monoid는 Semigroup을 extends한다. 만약 empty가 필요없다면 다음과 같이 작성할 수 있다.

#+BEGIN_SRC scala
import cats.Semigroup

Semigroup[String].combine("Hi ", "there")
// res4: String = Hi there
#+END_SRC

Monoid를 위한 type class instance는 Chapter1에서 설명한 표준적인 방법으로 cats.instance에 들어있다. 예를 들어, 만약 우리가 Int를 위한 instance를 땡겨오고 싶다면, cats.instance.int를 import하자

#+BEGIN_SRC scala
import cats.Monoid
import cats.instances.int._ // for Monoid

Monoid[Int].combine(32, 10)
// res5: Int = 42
#+END_SRC

이와 비슷하게, cats.instance.int와 cats.instances.option의 instance를 조합해서 Monoid[Option[Int]]를 만들수도 있다.

#+BEGIN_SRC scala
import cats.Monoid
import cats.instances.int._    // for Monoid
import cats.instances.option._ // for Monoid

val a = Option(22)
// a: Option[Int] = Some(22)

val b = Option(20)
// b: Option[Int] = Some(20)

Monoid[Option[Int]].combine(a, b)
// res6: Option[Int] = Some(42)
#+END_SRC

Chapter 1의 import를 위한 더 편리한 list를 참조하자.

*** Monoid Syntax
Cats는 combine method를 위해 |+|라는 operator로 syntax를 제공한다. combine는 기술적으로 Semigroup에 있기 때문에, cats.syntax.semigroup을 import함으로써 syntax에 접근할 수 있다.

#+BEGIN_SRC scala
import cats.instances.string._ // for Monoid
import cats.syntax.semigroup._ // for |+|

val stringResult = "Hi " |+| "there" |+| Monoid[String].empty // stringResult: String = Hi there

import cats.instances.int._ // for Monoid

val intResult = 1 |+| 2 |+| Monoid[Int].empty
// intResult: Int = 3
#+END_SRC

*** Exercise: Adding All The Things
** Application of Monoids
이제 monoid가 먼지 알게 됬다. monoid는 adding 혹은 combining의 개념을 추상화 한것이다. 그런데 이게 어디에 유용할까? 여기에 monoid가 유용하게 사용될 수 있는 몇가지 아이디어들이 있다. 각 case study들에 대한 구체적인 내용은 책의 뒤에서 알아볼 것이다.
*** Big Data
Spark이나 Hadoop같은 big data application에서는 주어진 fault tolerance와 scalability에서 많은 machine간에 data analysis를 분산해야 한다. 이에 대한 말씀은 각 machine이 데이터 일부분의 결과를 돌려주고 결국에는 이를 combine해서 최종 결과를 얻어야 된다는 것을 의미한다. 이런 경우는 우리가 monoid의 관점에서 볼 수 있다.
만약 우리가 website의 전체 방문자수를 계산하고자 한다면, data의 각 port에서 Int를 계산한다는 것을 의미한다. Int의 monoid instance는 addition이고, 이는 부분적인 값들을 합치기 위한 적합한 방법임을 알고 있다.
만약 website가 받은 unique visitor가 얼마인지를 알고 싶다고 하면, 이는 data의 각 portion에서의 Set[User]를 구축하는 것과 같다. 우리는 Set을 위한 monoid instance가 set union인 것을 알고 있으며, 이는 부분적인 값들을 합치기 위한 적합한 방법임을 알고 있다.
만약 server log로부터 99% 그리고 95%의 response time을 계산하려고 한다면 우리는 monoid인 QTree라고 불리는 데이터 structure를 사용할 수 있다.
여기서 아이디어를 얻었기를 바란다. 대부분 우리가 큰 데이터 셋에서 구하고자 하는 모든 분석은 monoid이며, 이 아이디어로부터 표현력있고 강력한 분석 시스템을 만들어낼 수 있다. 이것이 바로 Twitter가 Algebird와 Summingbird프로젝트에서 하고 있는 방식이다. 우리는 이 아이디어를 map-reduce case study까지 확장해볼 수 있다.

*** Distributed Systems
분산 시스템에서, 서로 다른 머신은 data의 서로 다른 부분의 내용을 처리한다. 예를 들어, 하나의 머신은 다른 머신이 받지 않은 update 정보를 받을 수도 있다. 이 다른 관점을 조정시키기 위해서, 모든 머신은 더 이상의 update가 도착하지 않는 다면 같은 데이터를 유지한다. 이를 eventual consistency라고 한다.

data type의 특정한 클래스가 이 조정을 지원한다. 이 data type들은 commutative replicated data type(CRDTs)이라고 불린다. 주요 동작은 두 instance에 있는 모든 정보를 수집한 결과를 가지고 두 데이터 instance를 조합하는 것이다. 이 동작은 monoid instance를 가지는 것에 의존한다. CRDT case study에 대한 것은 뒤에서 더 살펴보자

*** Monoids in the Small
위의 두가지 예제는 monoid가 entire system archtecture에 정보를 제공하는 예제이다. monoid를 가지고 작은 코드 조각들을 더 쉽게 만들수 있도록 하는 많은 경우들이 있다. 이런 것들은 이 책의 case study에서 많은 예제로 살펴볼 것이다.

** Summary
이 장에서는 큰 마일스톤을 달성했다. 근사한 functional programming name을 가진 첫번째 type class를 다루었다.

- Semigroup은 addition 혹은 combination operation을 나타낸다.
- Monoid는 Semigroup을 상속하고 추가적으로 identity나 "zero" element를 추가한다.

Semigroup과 Monoid는 세가지를 import함으로써 사용할 수 있다:type class, 다루어야 하는 type의 instance들, 그리고 |+| operator를 쓸 수 있게 해주는 semigroup syntax이다

#+BEGIN_SRC scala
import cats.Monoid
import cats.instances.string._ // for Monoid
import cats.syntax.semigroup._ // for |+|

"Scala" |+| " with " |+| "Cats"
// res0: String = Scala with Cats
#+END_SRC

#+BEGIN_SRC scala
import cats.instances.int._    // for Monoid
import cats.instances.option._ // for Monoid
Option(1) |+| Option(2)
// res1: Option[Int] = Some(3)
import cats.instances.map._ // for Monoid

val map1 = Map("a" -> 1, "b" -> 2)
val map2 = Map("b" -> 3, "d" -> 4)

map1 |+| map2
// res3: Map[String,Int] = Map(b -> 5, d -> 4, a -> 1) 

import cats.instances.tuple._ // for Monoid

val tuple1 = ("hello", 123)
val tuple2 = ("world", 321)

tuple1 |+| tuple2
// res6: (String, Int) = (helloworld,444)
#+END_SRC

또한 Monoid의 instance를 가지는 어떤 type과도 동작할 수 있는 generic code를 작성할 수도 있다.

#+BEGIN_SRC scala
def addAll[A](values: List[A])
      (implicit monoid: Monoid[A]): A =
  values.foldRight(monoid.empty)(_ |+| _)

add(List(1, 2, 3)
add(List(None, Some(1), Some(2)))
#+END_SRC

Monoid는 Cats의 훌륭한 gateway이다. 이해하기 쉽고 사용하기 간단하다. 하지만 이는 abstraction 관점에서 Cats가 우리가 가능하게 해주는 부분의 아주 작은 일부분일 뿐이다. 다음 챕터에서는 functor를 살펴볼 것이다. functor는 사랑하는 map method의 화신인 type class이다. 재미는 여기서부터 시작이다.

* Functors
이 챕터에서는 *functors*에 대해서 살펴볼 것이다. functor는 List, Option 및 다른 수많은 가능한 것들 중에 operation의 순서를 표현할 수 있도록 해주는 추상화이다. Functor 자체는 그렇게 유용하지 않지만, *monads*와 *applicative functors*와 같은 특별한 functor들은 Cats에서 매우 일반적으로 사용되는 추상화들이다
** Examples of Functors
functor는 map method를 가지고 있는 것은 어떤 것이든 functor라고 할 수 있다. 아마 map을 가지고 있는 많은 타입들을 알고 있을 것이다: Option, List, Either 등

일반적으로 List를 순회할 때 map을 처음 만나게 된다. 하지만, functor를 이해하기 위해서는 method를 다르게 생각해볼 필요가 있다. list를 순회한다고 보기 보다는, 모든 값들을 변환한다고 생각해야 한다. 적용하기 위한 function을 정의하면, map은 이 function이 모든 item에 적용된다는 것을 보장한다. 값은 변경되지만 list의 구조는 그대로 남는다.

#+BEGIN_SRC scala
 List(1, 2, 3).map(n => n + 1)
// res0: List[Int] = List(2, 3, 4)
#+END_SRC 

이와 유사하게, Option에 map을 사용할 때, content를 변환하면서도 Some이나 None context를 변경하지 않을 수 있다.

[[file:./images/Figure3.1.png]]

동일한 원칙이 Left, Right context와 함께 Either에 적용된다. 이 transformation의 일반적인 개념은 서로 다른 data type간의 map의 해동이 어떻게 연결되는가에 대한 것이다.

map이 변환되지 않은 context의 구조를 벗어나기 때문에, 우리는 초기 data 구조의 content에서 여러번의 computation을 반복해서 하기 위해 map을 반복해서 호출할 수 있다.

#+BEGIN_SRC scala
List(1, 2, 3).
  map(n => n + 1).
  map(n => n * 2).
  map(n => n + "!")
// res1: List[String] = List(4!, 6!, 8!)
#+END_SRC 

map을 iteration pattern으로 생각하면 안된다. 관련된 data type에 의해 작성된 몇몇 문제들을 무시하고 값에 대한 계산을 순차적으로 처리할 수 있는 방법이라고 생각해야 한다

- Option: 값이 있거나 혹은 없거나
- Either: 값 혹은 error
- List: zero 혹은 다른 값들

** More Examples of Functors
List, Option, Either의 map method는 함수들을 미리 적용할 수 있다. 하지만, 순차적인 computation이라는 아이디어는 이거보다 훨씬 더 general하다. 다른 방식의 페턴을 적용하는 몇몇 다른 functor의 행동을 살펴보자.

*Future*
Future는 큐잉하고 predecessor를 완전하게 적용함으로써  비동기적인 computation을 순차적으로 할 수 있는 functor이다. Future의 map method의 type signature는 위의 signature와 동일한 형태를 가진다. 하지만, 그 동작은 매우 다르다.

Future를 사용할 때에는, Future의 내부 상태를 전혀 보장할 수 없다. wrapped computation은 ongoing, complete, rejected일 수 있다. 만약 Future가 complete이면, mapping function이 바로 호출될 수 있다. 만약 complete가 아니라면, 몇몇 쓰레드풀이 function call을 큐잉하고 나중에 다시 돌아온다. function이 호출될 때를 알지 못하지만 어떤 순서로 호출될 것인지는 알 수 있다. 이러한 방식에서, Future는 List, Option, Either에서 본 것과 동일한 순서의 행동을 제공한다.

#+BEGIN_SRC scala
import scala.concurrent.{Future, Await}
import scala.concurrent.ExecutionContext.Implicits.global import scala.concurrent.duration._

val future: Future[String] =
  Future(123).
    map(n => n + 1).
    map(n => n * 2).
    map(n => n + "!")

Await.result(future, 1.second)
// res3: String = 248!
#+END_SRC

#+BEGIN_EXAMPLE
Futures and Referential Transparency

Scala의 Future는 pure functional programming의 예제로서는 그닥 좋지 않다. 왜냐하면 Future가 referentially transparent하지 않기 때문이다. Future는 항상 처리하고 결과를 캐싱한다.그리고 이 행동을 수정할 수 있는 방법이 없다. 다시 말해 side-effect가 있는 computation을 Future로 싼다면 예측할수 없는 결과를 얻을 수 있다. 예를 들면:

import scala.util.Random
val future1 = {
  // Initialize Random with a fixed seed:
  val r = new Random(0L)

  // nextInt has the side-effect of moving to
  // the next random number in the sequence:
  val x = Future(r.nextInt)

  for {
    a <- x
    b <- x
  } yield (a, b)
}

val future2 = {
  val r = new Random(0L)

  for {
    a <- Future(r.nextInt)
    b <- Future(r.nextInt)
  } yield (a, b)
}

val result1 = Await.result(future1, 1.second)
// result1: (Int, Int) = (-1155484576,-1155484576)
val result2 = Await.result(future2, 1.second)
// result2: (Int, Int) = (-1155484576,-723955400)

이상적으로 result1과 result2는 같은 값을 가져야 한다. 하지만, future1의 연산이 nextInt를 한번 호출하고 future2의 연산이 nextnt를 두번 호출한다. 왜냐하면 nextInt는 각각에 대해서 매번 다른 결과를 return하기 떄문이다.

이런 차이의 종류는 Future와 side-effect를 포함한 프로그램에 대한 추론을 어렵게 한다. Future 행동의 문제가 되는 부분은 또 있다. 사용자가 연산이 수행되어야만 할 때 지시할 수 있도록 하는 것보다 항상 즉시 연산을 시작한다는 것이다. 더 자세한 정보는 이 훌륭한 Stack Overflow answer를 참조하자
#+END_EXAMPLE

만약 Future가 referentially transparent하지 않다면, 아마 또다른 유사한 data-type을 살펴봐야만 할 것이다. 이것을 인지해야 한다. 

*Functions(?!)*
하나의 인자를 가지는 function도 functor이다. 이걸 확인하려면 type을 가지고 약간 장난을 쳐야한다. function A => B는 두개의 type parameter를 가진다. parameter type A와 result type B이다. 정확한 모양을 강압하기 위해서, parameter type을 고정하고 result type을 다양하게 할 수 있다.

- X => A로 시작
- A => B인 function을 제공
- X => B를 얻음

만약 X => A를 MyFunc[A]라고 하면, 이 챕터의 다른 예제에서 보아왔던 type과 같은 패턴을 볼 수 있다. Future 3.3에서 이런걸 봤다.

- MyFunc[A]로 시작
- A => B인 function을 제공
- MyFunc[B]를 얻음

다시 말해, Function1에 대한 "mapping"은 function composition이다. 

#+BEGIN_SRC scala
import cats.instances.function._ // for Functor
import cats.syntax.functor._     // for map

val func1: Int => Double =
  (x: Int) => x.toDouble

val func2: Double => Double =
  (y: Double) => y * 2

(func1 map func2)(1)     // composition using map
// res7: Double = 2.0

(func1 andThen func2)(1) // composition using andThen
// res8: Double = 2.0

func2(func1(1))          // composition written out by hand
// res9: Double = 2.0
#+END_SRC

어떻게 이것이 순차적인 operation의 일반적인 패턴과 연관이 있을까? 만약 그렇게 생각한다면, function composition은 순차적인것이다. 하나의 동작을 수행하는 함수로 시작해서 항상 우리는 그 chain에 다른 동작을 추가하기 위해서 map을 사용한다. map을 호출하는 것은 실제로 어떤 동작도 수행하는 것이 아니지만, 만약 인자를 모든 동작의 마지막 함수에 전달하면, 모든 동작은 순차적으로 실행된다. 이것을 Future와 유사한 lazily queueing up operation이라고 생각할 수 있다.

#+BEGIN_SRC scala
val func =
  ((x: Int) => x.toDouble).
    map(x => x + 1).
    map(x => x * 2).
    map(x => x + "!")

func(123)
// res10: String = 248.0!
#+END_SRC

#+BEGIN_QUOTE
/Partial Unification/
위의 예제가 동작할 수 있도록 하기 위해서 다음의 compiler option을 build.sbt에 추가할 필요가 있다.

#+BEGIN_SRC scala
scalacOptions += "-Ypartial-unification"
#+END_SRC

그렇지 않으면 컴파일러 에러가 발생할 것이다.

#+BEGIN_SRC scala
func1.map(func2)
// <console>: error: value map is not a member of Int => Double // func1.map(func2)
#+END_SRC

왜 이런 일이 일어나는지는 Section 3.8에서 자세히 살펴볼 것이다.
#+END_QUOTE

** Definition of a Functor


#+BEGIN_SRC scala
package cats

import scala.language.higherKinds

trait Functor[F[_]] {
  def map[A, B](fa: F[A])(f: A => B): F[B]
}
#+END_SRC

#+BEGIN_QUOTE
Functor Laws

Functor는 우리가 하나씩 작은 동작을 순차적으로 처리하거나 mapping전에 하나의 큰 function으로 combine하던 동일한 semantic을 보장한다. 이를 보장하기 위해서 다음의 규칙을 만족해야만 한다.

/Identity/: identity function과 함께 map을 호출하는 것은 아무것도 안하는 것과 동일하다

#+BEGIN_SRC scala
fa.map(a => a) == fa
#+END_SRC

/Composition/: 두 function인 f와 g를 mapping하는 것은 f를 mapping하고 g를 mapping하는 것과 같다.

#+BEGIN_SRC scala
fa.map(g(f(_))) == fa.map(f).map(g)
#+END_SRC
#+END_QUOTE

** Aside: Higher Kinds and Type Constructors
Kind는 type을 위한 type이다. Kind는 type에 있는 많은 "holes"을 설명한다. hole을 가지고 있지 않은 일반적인 type들과 type을 생성하기 위해서 채워넣을 수 있는 hole을 가지고 있는 "type constructors"를 구별한다. 

에를 들어, List는 하나의 hole을 가진 type constructor이다. List[Int]나 List[A]와 같은 regular type을 만들어 내는 parameter를 정의해서 hole을 채울 수 있다. 이 트릭은 generic type의 type constructor를 혼동시키지 않는다. List는 type constructor이고 List[A]는 type이다:

#+BEGIN_SRC scala
List    // type constructor, takes one parameter
List[A] // type, produced using a type parameter
#+END_SRC

function과 value를 가진 유사한 analogy가 있다. Function은 "value constructor"이다-value constructor는 parameter를 제공할 때 value를 생성할 수 있다.

#+BEGIN_SRC scala
math.abs    // function, takes one parameter
math.abs(x) // value, produced using a value parameter
#+END_SRC

Scala에서는 underscore를 사용해서 type constructor를 정의한다. 일단 한번 type constructor를 정의해놓으면 간단한 identifier로 참조할 수 있다.

#+BEGIN_SRC scala
// Declare F using underscores:
def myMethod[F[_]] = {
  // Reference F without underscores:
  val functor = Functor.apply[F]
  // ...
}
#+END_SRC

function의 parameter를 정의하는 것은과 이를 참조하는 것은 유사하다

#+BEGIN_SRC scala
// Declare f specifying parameters:
val f = (x: Int) => x * 2

// Reference f without parameters:
val f2 = f andThen f
#+END_SRC

type constructor의 지식을 가지고, 우리는 List, Option, Future, MyFunc와 같은 type alias들 같은 어떤 single-parameter type constructor를 가진 instance를 생성할 수 있도록 하는 Functor에 대한 Cats definition을 살펴보자

#+BEGIN_QUOTE
/Language Feature Imports/

Higher kinded types는 Scala에서 advanced language feature로 생각된다. A[_] 문법을 가진 type constructor를 정의할 때마다, 컴파일러로부터 warning을 없애기 위해 higher kinded type language feature를 "enabled"할 필요가 있다. "language import"로 이를 켜거나

#+BEGIN_SRC scala
import scala.language.higherKinds
#+END_SRC

build.sbt에 scalacOptions를 추가하자

#+BEGIN_SRC scala
scalacOptions += "-language:higherKinds"
#+END_SRC

가능하면 명시적으로 language import를 사용할 것이다. 하지만 실제로는 scalacOptions flag를 사용하는 것이 더 간단하고 코드도 짧다
#+END_QUOTE

** Functors in Cats
Cats에서의 functor의 구현을 살펴보자. monoid를 위해서 했던 부분을 살펴볼 것이다: type class, instances, syntax

*** The Functor Type Class
functor type class는 cats.Functor이다. companion object에 있는 표준 Functor.apply를 사용해서 instance를 얻을수 있다. 일반적으로 기본 instance는 cats.instances package에 있는 type에 의해 조정된다.

#+BEGIN_SRC scala
import scala.language.higherKinds
import cats.Functor
import cats.instances.list._   // for Functor
import cats.instances.option._ // for Functor

val list1 = List(1, 2, 3)
// list1: List[Int] = List(1, 2, 3)

val list2 = Functor[List].map(list1)(_ * 2)
// list2: List[Int] = List(2, 4, 6)

val option1 = Option(123)
// option1: Option[Int] = Some(123)

val option2 = Functor[Option].map(option1)(_.toString) 
// option2: Option[String] = Some(123)
#+END_SRC

Functor는 A => B type의 함수를 F[A] => F[B] type을 같는 functor로 변환하는 lift method를 제공한다. 

#+BEGIN_SRC scala
val func = (x: Int) => x + 1
// func: Int => Int = <function1>

val liftedFunc = Functor[Option].lift(func)
// liftedFunc: Option[Int] => Option[Int] = cats.Functor$$Lambda$12952101985314@120e192a

liftedFunc(Option(1))
// res0: Option[Int] = Some(2)
#+END_SRC

*** Functor Syntax
Functor를 위한 syntax에 의해서 제공되는 main method는 map이다. Options과 Lists를 가진 Functor를 증명하는 것은 어렵고 Scala compiler는 항상 extension method에 있는 built-in method를 항상 선호할 것이다. 우리는 이를 두가지 예제를 통해 살펴볼 것이다.

우선 function간의 mapping을 보자. Scala의 Function1 type은 map method를 안가지고 있으므로 naming conflict는 없다:

#+BEGIN_SRC scala
import cats.instances.function._ // for Functor
import cats.syntax.functor._     // for map

val func1 = (a: Int) => a + 1
val func2 = (a: Int) => a * 2
val func3 = (a: Int) => a + "!"
val func4 = func1.map(func2).map(func3)

func4(123)
// res1: String = 248!
#+END_SRC

또다른 예제를 보자. 이번에는 functor들을 추상화할 것이고 어떤 특정한 type으로도 돌리지 않을 것이다. 어떤 functor context든 간에 number에 대한 방정식을 수행하는 method를 작성할 것이다.

#+BEGIN_SRC scala
def doMath[F[_]](start: F[Int])
    (implicit functor: Functor[F]): F[Int] =
  start.map(n => n + 1 * 2)

import cats.instances.option._ // for Functor
import cats.instances.list._   // for Functor

doMath(Option(20))
// res3: Option[Int] = Some(22)

doMath(List(1, 2, 3))
// res4: List[Int] = List(3, 4, 5)

#+END_SRC

이것이 어떻게 동작하는지 설명하기 위해서 cats.syntax.functor에 있는 map method의 정의를 살펴보자. 아래는 코드를 간략화한 버전이다

#+BEGIN_SRC scala
implicit class FunctorOps[F[_], A](src: F[A]) {
  def map[B](func: A => B)
      (implicit functor: Functor[F]): F[B] =
    functor.map(src)(func)
}
#+END_SRC

compiler는 사용가능한 built-in map이 없는 모든 곳에서 map method를 삽입하기 위해 이 확장 method를 사용할 수 있다.

#+BEGIN_SRC scala
foo.map(value => value + 1)
#+END_SRC

foo가 built-in map method를 가지고 있지 않다고 가정하면, compiler는 잠재적인 에러를 감지하고 code를 수정하기 위해서 FunctorOps에 있는 expression을 싼다.

#+BEGIN_SRC scala
new FunctorOps(foo).map(value => value + 1)
#+END_SRC

FunctorOps의 map method는 파라미너로 implicit Functor를 필요로 한다. 이것은 이 코드가 해당 scope에 expr1을 위한 Functor를 가질 때에만 컴파일된다는 것을 의미한다. 만약 Functor가 scope에 없다면, 컴파일 에러가 날 것이다:

#+BEGIN_SRC scala
final case class Box[A](value: A)

val box = Box[Int](123)

box.map(value => value + 1)
// <console>:34: error: value map is not a member of Box[Int]
//        box.map(value => value + 1)
//
#+END_SRC

*** Instances for Custom Types
map method를 정의해서 간단하게 functor를 정의할 수 있다. 아래는 Option을 위한 Functor의 예제이다. 사실 cats.instances에 이미 Option을 위한 Functor가 있지만 말이다. 구현은 사소한 것이다-간단하게 Option의 map method를 호출해보자

#+BEGIN_SRC scala
implicit val optionFunctor: Functor[Option] =
  new Functor[Option] {
    def map[A, B](value: Option[A])(func: A => B): Option[B] = 
      value.map(func)
}
#+END_SRC

때로는 instance에 의존성을 주입해야할 필요도 있따. 예를 들어, 만약 Future를 위한 custom Functor를 정의해야만 한다면 future.map에 implicit ExecutionContext parameter를 필요로 할 수도 있따. functor.map에 추가적인 파라미터를 더 넘길수 없으므로 instance를 생성할 때 의존성을 주입해야 한다:

#+BEGIN_SRC scala
import scala.concurrent.{Future, ExecutionContext}

implicit def futureFunctor(implicit ec: ExecutionContext): Functor[Future] = 
  new Functor[Future] {
    def map[A, B](value: Future[A])(func: A => B): Future[B] =
      value.map(func)
  }
#+END_SRC

Future를 위한 Functor를 소환할 때마다, 바로 Functor.apply를 사용하거나 간접적으로 map 확장 method를 통할수도 있는데, 컴파일러는 implicit resolutiondmfh futureFunctor를 위치시키고 재귀적으로 호출한 쪽에 있는 ExecutionContext를 찾을 것이다. 이는 다음과 같은 확장이다:

#+BEGIN_SRC scala
// We write this:
Functor[Future]

// The compiler expands to this first:
Functor[Future](futureFunctor)

// And then to this:
Functor[Future](futureFunctor(executionContext))
#+END_SRC 

*** Exercise: Branching out with Functors

** Contravariant and Invariant Functors

*** Contravariant Functors and the contramap Method
우리의 첫번째 type class인 contravariant functor는 chain에 operation을 "덧붙일 수 있는" contramap이라는 operation을 제공한다. 일반적인 type signature는 Figure 3.5에서 볼 수 있다.

contramap method는 /transformation/을 표현하는 data type을 위해서만 의미가 있다. 예를 들어, function A => B를 통해 Option[B] backward에 있는 값을 feed할 수 있는 방법은 없다. 하지만, Chapter 1에서 논의했던 대로 Printable type class를 위한 contramap을 정의할 수 있다.

#+BEGIN_SRC scala
trait Printable[A] {
  def format(value: A): String
}
#+END_SRC 

Printable[A]는 A를 String로 transformation한다는 것을 표현한다. Printable[A]의 contramap method는 type B => A의 함수 Func를 받고 새로운 Printable[B]를 생성한다:

#+BEGIN_SRC scala
trait Printable[A] {
  def format(value: A): String
  def contramap[B](func: B => A): Printable[B] =
    ???
}

def format[A](value: A)(implicit p: Printable[A]): String = 
  p.format(value)
#+END_SRC

**** Exercise: Showing off with Contramap 

*** Invariant functors and the /imap/ method
Invariant functors는 map과 contramap을 조합한것과 동일한 정보를 제공하는 imap이라는 method를 구현한다. 만약 map이 chain에 function을 추가함으로써 새로운 type class를 생성한다면, contramap은 새로운 type class instance를 생성해서 chain에 추하고, imap은 이 인스턴스들을 bidirectional transformation의 pair를 통해서 생성할 것이다.

이에 대한 가장 좋은 예는 어떤 data type으로 encoding하고 decoding하는 type class이다. 예를 들면 Play JSON's Format and scodec의 Codec같은 것말이다. String으로부터 혹은 String으로 encoding하고 decoding하는 것을 지원하도록 Printable을 개량함으로써 자체적인 Codec을 생성할 수 있다.

#+BEGIN_SRC scala
trait Codec[A] {
  def encode(value: A): String
  def decode(value: String): A
  def imap[B](dec: A => B, enc: B => A): Codec[B] = ???
}

def encode[A](value: A)(implicit c: Codec[A]): String = 
  c.encode(value)

def decode[A](value: String)(implicit c: Codec[A]): A = 
  c.decode(value)
#+END_SRC

~imap~ 의 type chart는 Figure 3.6에서 볼 수 있다. 만약 ~Codec[A]~ 를 가지고 function A =>B와 B => A의 쌍을 가진다면 ~imap~ method는 ~Codec[B]~ 를 생성한다:

예제 사용 예에서, encode와 decode method가 모두 no-op인 기본적인 ~Codec[String]~ 을 가진다고 상상해보자.

#+BEGIN_SRC scala
implicit val stringCodec: Codec[String] =
  new Codec[String] {
    def encode(value: String): String = value
    def decode(value: String): String = value
  }
#+END_SRC

~imap~ 을 사용하는 ~stringCodec~ 을 만드는 또다른 type을 위한 유용한 ~Codec~을 만들 수 있다:

#+BEGIN_SRC scala
implicit val intCodec: Codec[Int] =
  stringCodec.imap(_.toInt, _.toString)

implicit val booleanCodec: Codec[Boolean] =
  stringCodec.imap(_.toBoolean, _.toString)
#+END_SRC

#+BEGIN_QUOTE
Failure 다루기

~Codec~ type class의 decode method는 failure를 다루지 않는다는 걸 알아두자. 만약 우리가 더욱 정교한 관계를 가지는 모델링을 하고 싶다면, functor뿐만 아니라 /lense/와 /optic/을 살펴보아야 한다.

Optic은 이 책의 범위를 넘어선다. 하지만, Julien Truffaut의 Monocle이라는 라이브러리는 좋은 시작점이 될 것이다. 
#+END_QUOTE

**** Transformative Thinking with imap

#+BEGIN_QUOTE
What's With the Names?

"contravariance", "invariance", "covariance"의 관계는 무엇이고, functor와 다른 점은 무엇일까?

1.6.1에서 variance는 코드의 변경 없이 어떤 타입의 값을 다른 타입의 값으로 변경하기 위해서 필수적인 subtyping에 영향을 준다. 

Subtyping은 conversion으로 보일 수도 있다. 만약 B가 A의 subtype이라면, B는 항상 A로 변환될 수 있따.

이와 같이 function A => B가 존재한다면 B를 A의 subtype이라고 할 수도 있다. standard covariant functor가 정확히 이것을 말한다. 만약 F가 covariant functor라면 F[A]가 있고, A => B의 변환이 있는 곳마다, F[B]로 변환할 수 있다. 

contravariant functor는 정확히 반대상황을 말한다. 만약 F가 contravariant functor이면, F[A]를 가지고 B=>A의 변환이 필요한 곳마다 F[B]로 변환할 수 있다.

결론적으로 invariant functor는 function A => B를 통해서 F[A]에서 F[B]로 변환하고, 혹은 B => A를 이용해 F[B]에서 F[A]로 변환하는 것을 의미한다.     
#+END_QUOTE

** Contravariant and Invariant in Cats
Cats에서 cats.Contravariant와 cats.Invariant type class에 의해서 제공하는 contravariant와 invariant functor를 어떻게 구현하고 있는지 살펴보자. 

여기 간단하게 만든 코드가 있다

#+BEGIN_SRC scala
trait Contravariant[F[_]] {
  def contramap[A,B](fa: F[A])(f: B => A): F[B]
}

trait Invariant[F[_]] {
  def imap[A,B](fa: F[A])(f: A => B)(g: B => A): F[B]
}
#+END_SRC

*** Contravariant in Cats
Contravariant.apply method를 사용하는 Contravariant의 instance를 소환할 수 있다. Cats는 Eq, Show, Function1을 포함하는 parameter를 소비하는 data type의 instance를 제공한다. 여기 예제가 있다

#+BEGIN_SRC scala
import cats.Contravariant
import cats.Show
import cats.instances.string._

val showString = Show[String]

val showSymbol = 
  Contravariant[Show].contramap(showString)((sym: Symbol) =>s"'${sym.name}")

showSymbol.show('dave)
// res2: String = 'dave
#+END_SRC

더 편리하게, contramap 확장 method를 제공하는 cats.syntax.contravariant를 사용할 수도 있다.

#+BEGIN_SRC scala
import cats.syntax.contravariant._ // for contramap

showString.contramap[Symbol](_.name).show('dave)
// res3: String = dave
#+END_SRC

*** Invariant in Cats
다른 type을 위해서, Cats는 ~Monoid~ 를 위한 ~Invariant~ 의 instance를 제공한다. 이는 3.6.2에서 소개한 ~Codec~ 예제와는 조금 다르다. 아래는 ~Monoid~ 의 코드이다

#+BEGIN_SRC scala
package cats

trait Monoid[A] {
  def empty: A
  def combine(x: A, y: A): A
}
#+END_SRC

Scala의 Symbol type을 위한 ~Monoid~ 를 제공하고자 한다고 생각해보자. Cats는 ~Symbol~ 을 위한 ~Monoid~ 를 제공하지 않지만 비슷한 type인 String을 위한 ~Monoid~ 를 제공한다. 빈 ~String~ 을 위한 ~empty~ method와 다음과 같이 동작하는 ~combine~ method를 가지는 새로운 semigroup을 만들 수 있다.

1. 두 개의 ~Symbol~ 을 파라미터로 받는다.
2. ~Symbol~ 을 ~String~ 으로 변환한다
3. ~Monoid[String]~ 을 사용해서 ~String~ 을 combine한다.
4. result를 다시 ~Symbol~ 로 변환한다

~String~ => ~Symbol~ 과 ~Symbol~ => ~String~ type의 함수를 파라미터로 받는 ~imap~ 을 사용하는 ~combine~ 을 구현해보자. 여기에 ~cats.syntax.invariant~ 가 제공하는 ~imap~ 확장 method를 이용해서 작성한 코드가 있다.

#+BEGIN_SRC scala
import cats.Monoid
import cats.instances.string._ // for Monoid
import cats.syntax.invariant._ // for imap
import cats.syntax.semigroup._ // for |+|

implicit val symbolMonoid: Monoid[Symbol] = 
  Monoid[String].imap(Symbol.apply)(_.name)

Monoid[Symbol].empty
// res5: Symbol = '

'a |+| 'few |+| 'words
// res6: Symbol = 'afewwords
#+END_SRC

** Aside: Partial Unification
3.2에서 재미있는 compiler error를 살펴봤다. 다음의 코드는 -Ypartial-unification compiler flag를 enable했을 때 제대로 컴파일된다. 

#+BEGIN_SRC scala
import cats.Functor
import cats.instances.function._ // for Functor
import cats.syntax.functor._     // for map

val func1 = (x: Int)    => x.toDouble
val func2 = (y: Double) => y * 2

val func3 = func1.map(func2)
// func3: Int => Double = scala.runtime.AbstractFunction1$$Lambda$23131769218156@6b5ae8b2
#+END_SRC

하지만 flag가 없으면 실패한다.

#+BEGIN_SRC scala
val func3 = func1.map(func2)
// <console>: error: value map is not a member of Int => Double 
// val func3 = func1.map(func2)
#+END_SRC

확실히 "partial unification"은 부가적인 compile 행동이다. 이 행동에 대해서 알아보고 몇몇 사용예를 논의해보자

*** Unifying Type Constructors
위의 ~func1.map(func2)~ 와 같은 expression을 컴파일하기 위해서, compiler는 ~Function1~ 을 위한 ~Functor~ 를 찾아야만 한다. 하지만, ~Functor~ 는 하나의 parameter를 가지는 type constructor를 받는다:

#+BEGIN_SRC scala
trait Functor[F[_]] {
  def map[A, B](fa: F[A])(func: A => B): F[B]
}
#+END_SRC

그리고 ~Function1~ 은 두가지 type parameter를 가진다(function argument와 result type)

#+BEGIN_SRC scala
trait Function1[-A, +B] {
  def apply(arg: A): B
}
#+END_SRC

compiler는 ~Functor~ 에게 넘길 올바른 종류의 type constructor를 생성하기 위해서 ~Function1~ 의 두 가지 parameter 중 하나를 고쳐야만 한다. 두 가지 조건이 있다

#+BEGIN_SRC scala
type F[A] = Int => A
type F[A] = A => Double
#+END_SRC

이러한 것들의 형식은 올바른 선택이다. 하지만, Scala compiler의 이전 버전은 이런 추론을 할 수 없었다. 이 유명하지 않은 제약사항은 SI-2712인데, compiler가 다른 arity를 가지는 type constructor의 "unifying" 을 막았다. 이 컴파일러 제약사항은 이제 고쳐졌지만 ~build.sbt~ 의 compiler flag를 통해서만 enable해야 한다.

#+BEGIN_SRC scala
scalacOptions += "-Ypartial-unification"
#+END_SRC

*** Left-to-Right Elimination

Scala compiler의 partial unification은 왼쪽에서 오른쪽으로 type parameter를 수정하면서 동작한다. 위의 예제에서, compiler는 ~Int => Double~ 에 있는 ~Int~ 를 수정하고 type ~Int => ?~ 의 function을 위한 ~Functor~ 를 찾는다.

#+BEGIN_SRC scala
type F[A] = Int => A

val functor = Functor[F]
#+END_SRC

이 left-to-right 제거는 ~Function1~ 과 ~Either~ 와 같은 type을 위한 ~Functor~ 를 포함한 다양한 일반적인 시나리오에서 동작할 수 있다.

#+BEGIN_SRC scala
import cats.instances.either._ // for Functor

val either: Either[String, Int] = Right(123)
// either: Either[String,Int] = Right(123)

either.map(_ + 1)
// res2: scala.util.Either[String,Int] = Right(124)
#+END_SRC

하지만, left-to-right 제거가 올바르지 않은 선택이 되지 않을 상황도 있다. 예를 들면 습관적으로 left-biase된 ~Either~ 의 equivalent인 Scalatic에서의 ~Or~ type이 그 예이다:

#+BEGIN_SRC scala
type PossibleResult = ActualResult Or Error
#+END_SRC

또 하나의 예는 ~Function1~을 위한 ~Contravariant~ functor이다.

~Function1~ 을 위한 covariant ~Functor~ 가 ~andThen~-style left-to-right function composition을 구현하다면 ~Contravariant~ functor는 ~compose-style~ right-to-left composition을 구현한다. 다시 말해 다음의 expression은 동일하다:

#+BEGIN_SRC scala
val func3a: Int => Double =
  a => func2(func1(a))

val func3b: Int => Double =
  func2.compose(func1)

// Hypothetical example. This won't actually compile:
val func3c: Int => Double =
  func2.contramap(func1)
#+END_SRC

만약 실제로 이를 수행한다면, 코드는 컴파일되지 않을 것이다.

#+BEGIN_SRC scala
import cats.syntax.contravariant._ // for contramap 

val func3c = func2.contramap(func1)
// <console>:27: error: value contramap is not a member of Double => Double
// val func3c = func2.contramap(func1) //
#+END_SRC

여기서 문제는 ~Function1~ 을 위한 ~Contravariant~ 는 Fiture 3.7에서와 같이 오른쪽에서 왼쪽으로 type parameter를 제거하기 위해서 return type을 수정하고 compiler가 요구하는 parameter type을 남긴다.

#+BEGIN_SRC scala
type F[A] = A => Double
#+END_SRC

compiler는 left-to-right bias때문에 간단히 실패한다. Function1의 parameter를 flip하는 type을 생성함으로써 이를 증명할 수 있다.

#+BEGIN_SRC scala
type <=[B, A] = A => B

type F[A] = Double <= A
#+END_SRC

만약 <=의 instance로서 func2를 re-type하면 elimination의 요구되는 순서를 reset하고 요구되는 ~contramap~ 을 호출할 수 있다.

#+BEGIN_SRC scala
val func2b: Double <= Double = func2

val func3c = func2b.contramap(func1)
// func3c: Double <= Int = scala.runtime.AbstractFunction1$$Lambda$2313/1769218156@656e1369
#+END_SRC

func2와 func2b의 다른점은 순전히 syntatic이다 둘 다 같은 값을 참고하고 type alias는 완벽하게 compatible하다. 놀랍게도 이 간단한 rephrasing은 충분히 compiler에게 문제를 풀기 위해 필요한 힌트를 제공한다.

이런 종류의 right-to-left elminination을 필요로 하는 것은 드물다. 대부분의 multi-parameter type constructor는 right-biased로 디자인되었고 compiler의 의해서 지원되는 left-to-right elimination이 필요한 것은 out of box이다. 하지만 ~Ypartial-unification~ 과 elemination 순서의 quirk를 아는 것은 유용하다. 

** Summary
Functor는 sequencing behaviour를 나타낸다. 이 챕터에서 functor의 세가지 타입을 살펴보았다.

- ~map~ method를 가지는 일반적인 covariant ~Functor~ 는 몇몇 context에서 값에 function을 적용하도록 한다. ~map~ 의 성공적인 호출은 이 function들이 predecessor의 결과를 파라미터로 받아들이면서 순서대로 처리되게 한다.

- ~contramap~ method를 가지는 ~Contravariant~ functor는 function들을 function-like context로 "prepend"하는 것을 보여준다. ~map~ 의 반대 순서에서 ~contramap~ 의 성공적인 호출은 이 function들을 순서대로 처리하게 한다.

- ~imap~ method를 가지는 ~Invariant~ functor는 bidirectional transformation을 표현한다.

일반적인 ~Functor~ 는 이 type class의 가장 일반적인 것들이지만, 그 자체로 사용되는 것은 드물다. Functor는 우리가 항상 사용하는 흥미로운 추상의 block을 구축할 수 있도록 한다. 다음의 chapter에서는 이러한 abstraction의 두 가지를 살펴볼 것이다 ~Monad~ 와 ~applicative~ functor 말이다

collection을 위한 ~Functor~ 는 매우 중요하다. 이 Functor는 각 element를 독립적으로 변환할 수 있다. 이러한 기능은 큰 collection에서 병렬 혹은 분산된 transformation을 가능하게 해준다. Hadoop과 같은 "map-resuce" framework에서 많이 사용되는 기술이다. 이 책의 뒷부분에서 Map-reduce cas study에서 좀 더 자세히 살펴보겠다. ~Contravariant~와 ~Invariant~ type class는 좀 덜 넓게 적용가능하지만 여전히 transformation을 표현하는 data type을 구축하는 데는 유용하다. Chapter 6에서 ~Semigroupal~ type class를 논의할 때 다시 살펴보자.


* Monads
~Monad~ 는 스칼라에서 가장 일반적인 추상화중 하나이다. 많은 스칼라 프로그래머들은 이름도 모르지만 빠르게 직감적으로 monad에 익숙해진다. 

monad는 생성자와 ~flatMap~ method를 갖는 모든 것이다. 우리가 지난 chapter에서 본 functor도 ~Option~, ~List~, ~Future~ 를 포함해서 모두 monad이다. monad를 지원하기 위한 특별한 syntax가 있다: 바로 ~for~ comprehension이다. 하지만 개념은 어디에나 존재함에도 불구하고, Scala standard library는 "~flatMapped~ 될 수 있는 것"을 아우르기 위한 concrete type이 부족하다. 이 type class는 Cats가 우리에게 줄 수 있는 이점 중 하나이다.

이 챕터에서 우리는 monad를 깊게 살펴볼 것이다. 몇가지 예제와 함께 시작할 예정이다. Cats에서의 monad에 대한 formal definition과 implementation을 살펴볼 것이다. 마지막으로, 아직까지 보지 못한 몇가지 흥미로운 monad를 해당 monad의 사용을 알려주는 소개와 예제를 제공하면서 살펴볼 것이다.

** What is Monad?
이 질문은 수천개의 블로그에서 의미야 어떻게 됬든 endofunctor의 범우에 있는 monoid와 함께 고양이, 맥시칸 요리만큼 다양한 개념을 포함한 설명과 비유를 포함해서 이야기된 것이다. monad를 설명하는 문제를 풀어보고 매우 간단하게 언급할 것이다:

monad는 ~sequencing computation~ 을 위한 매커니즘이다

쉽다~! 문제 해결! 우리가 functor에 대해서 이야기한 지난 챕터는 정확히 같은 것을 위한 control mechanism이다. 그렇다. 좀 더 논의가 필요할 것 같다...

Section 3.1에서 functor는 몇몇 complication을 무시하고 computation을 sequence할 수 있도록 해준다고 했다. 하지만, functor는 이 문제가 sequence의 시작에서 한번만 일어나도록만 제한할 수 있다. functor는 sequence에서의 각 step들에 문제를 다룰 수 없다. 

이 부분이 monad가 필요한 영역이다. monad의 ~flatMap~ method는 다음에 어떤 것을 할지, 중간 문제를 정의할 수 있게 해준다. Option의 ~flatMap~ 은 중간 ~Option~을 고려할 수 있게 한다. ~List~ 의 ~flatMap~ 은 중간 ~List~ 를 다룬다. 그리고 계속된다. 각각의 경우 ~flatMap~ 에 전달되는 function은 computation의 application-specific part를 정의하고 ~flatMap~ 자체는 ~flatMap~ 을 다시 할 수 있도록 하는 문제를 다룬다. 몇가지 예제를 살펴보자.

*Options*

~Option~ 은 값을 리턴하거나 하지 않을 computation을 sequence할 수 있도록 해준다. 몇몇 예제가 여기 있다:

#+BEGIN_SRC scala
def parseInt(str: String): Option[Int] =
  scala.util.Try(str.toInt).toOption

def divide(a: Int, b: Int): Option[Int] =
  if(b == 0) None else Some(a / b)
#+END_SRC

이 method 각각은 ~None~ 을 리턴하면 "fail"일 수 있다. ~flatMap~ method는 operation을 sequence할 때 이를 무시할 수 있도록 해준다:

#+BEGIN_SRC scala
def stringDivideBy(aStr: String, bStr: String): Option[Int] = 
  parseInt(aStr).flatMap { aNum =>
    parseInt(bStr).flatMap { bNum =>
      divide(aNum, bNum)
    } 
  }
#+END_SRC

semantic에 대해서는 잘 알고 있다:

- ~parseInt~ 의 첫번째 호출은 ~None~ 혹은 ~Some~ 을 리턴한다.
- 만약 이것이 ~Some~ 을 리턴하면, ~flatMap~ method는 우리의 function을 호출하고 ~aNum~ 이란 값을 넘겨준다.
- ~parseInt~ 의 두번째 호출은 ~None~ 혹은 ~Some~ 을 리턴한다.
- 만약 이것이 ~Some~ 을 리턴하면, ~flatMap~ method는 우리의 function을 호출하고 ~bNum~ 이란 값을 넘겨준다.
- ~divide~ 에 대한 호출은 우리의 결과인 ~None~ 혹은 ~Some~ 을 리턴한다.

각 단계에서, ~flatMap~ 은 우리의 function을 호출할지 말지 선택하고, 우리의 function은 sequence에서 다음 compuitation을 생성한다. Figure 4.1에서 볼 수 있다.

computation의 결과는 ~Option~ 이다. ~Option~ 은 다시 ~flatMap~ 을 호출할 수 있게 하고 sequence가 계속된다. 이는 우리가 알고 사랑하는 fail-fast error handling behavior를 할 수 있게 한다. 

#+BEGIN_SRC scala
stringDivideBy("6", "2")
// res1: Option[Int] = Some(3)

stringDivideBy("6", "0")
// res2: Option[Int] = None

stringDivideBy("6", "foo")
// res3: Option[Int] = None

stringDivideBy("bar", "2")
// res4: Option[Int] = None
#+END_SRC

모든 monad는 또한 functor이다. 그래서 새로운 monad를 소개하거나 소개하지 않을 computation을 sequence하기 위한 ~flatMap~ 과 ~map~ 모두에 의존할 수 있다. 추가로, 만약 우리가 ~flatMap~ 과 ~map~ 을 가지고 있다면 sequencing behaviour를 명확히 하기 위해 for comprehension을 사용할 수 있다: 

#+BEGIN_SRC scala
def stringDivideBy(aStr: String, bStr: String): Option[Int] = 
  for {
    aNum <- parseInt(aStr)
    bNum <- parseInt(bStr)
    ans  <- divide(aNum, bNum)
  } yield ans
#+END_SRC

*Lists*
스칼라 개발자로서 ~flatMap~ 에 처음 직면했을 때, ~List~ 를 탐색하기 위한 pattern으로서 이를 생각하는 경향이 있다. 이는 imperative for loop와 매우 유사한 for comprehension의 문법으로서 보강된다. 

#+BEGIN_SRC scala
for {
  x <- (1 to 3).toList
  y <- (4 to 5).toList
} yield (x, y)
// res5: List[(Int, Int)] = List((1,4), (1,5), (2,4), (2,5), (3,4),(3,5))
#+END_SRC

하지만 List의 monadic 행동을 강조할 수 있는 또다른 mental model이 있다. 만약 중간 결과의 집합으로서 ~List~ 를 생각한다면, ~flatMap~ permutation과 combination을 계산하기 위한 구조가 될 것이다. 

예를 들면, 위의 예제에서 for comprehension에 세가지의 가능한 x값과 두가지의 가능한 y값이 있다고 해보자. 이는 (x,y)의 6가지 가능한 값들이 있다는 것을 의미한다. ~flatMap~ 은 operation의 sequence를 언급하는 코드에서 이런 조합을 생성한다.

- x를 얻기
- y를 얻기
- tuple (x, y)를 생성

*Futures*
~Future~ 는 비동기라는 걱정 없이 computation을 sequence하는 monad이다: 
#+BEGIN_SRC scala
import scala.concurrent.Future
import scala.concurrent.ExecutionContext.Implicits.global import scala.concurrent.duration._

def doSomethingLongRunning: Future[Int] = ???
def doSomethingElseLongRunning: Future[Int] = ???

def doSomethingVeryLongRunning: Future[Int] =
  for {
    result1 <- doSomethingLongRunning
    result2 <- doSomethingElseLongRunning
  } yield result1 + result2
#+END_SRC

다시, 각 단계에서 돌아야 할 코드를 정의하고 ~flatMap~ 은 thread pool과 scheduler의 무섭게 내재된 모든 복잡성을 다룬다.

만약 ~Future~ 의 확장된 사용은, 위의 코드는 각 operation을 sequence하게 돌릴 것이다. 만약 ~flatMap~ 을 호출하는 nested call을 보여주는 for comprehension을 좀 더 명확하게 해보자:

#+BEGIN_SRC scala
def doSomethingVeryLongRunning: Future[Int] =
  doSomethingLongRunning.flatMap { result1 =>
    doSomethingElseLongRunning.map { result2 =>
      result1 + result2
    } 
  }
#+END_SRC

sequence에서의 각 Future는 이전의 Future로부터의 결과를 받는 함수에 의해서 생성된다. 다시 말해, computation의 각 단계는 이전 step이 한번 완료되었을 때에만 시작할 수 있다. Figure 4.2에서 ~flatMap~ 을 위한 type chart가 있다. 이 chart는 type A => Future[B]의 function parameter를 보여준다.

future를 parallel로 실행할 수 있다. 하지만 그건 또다른 이야기이고 다음에 이야기할 것이다. Monad는 모두 sequencing에 대한 것이다.

*** Definition of a Monad
위의 ~flatMap~ 에 대해서만 이야기하는 동안, monadic behaviour는 형식적으로 두가지 동작을 가진다: 

- pure, of type A => F[A];
- flatMap, of type (F[A], A => F[B]) => F[B]

pure는 plain value로부터 새로운 monadic context를 생성하기 위한 방법을 제공하는 구조들을 추상화한다. ~flatMap~ 은 context로부터 값을 추출하고 sequence의 다음 context를 생성하는 이미 논의된 sequencing step을 제공한다. 다음은 Cats에서의 Monad type class의 축약된 버전이다.

#+BEGIN_SRC scala
import scala.language.higherKinds

trait Monad[F[_]] {
  def pure[A](value: A): F[A]

  def flatMap[A, B](value: F[A])(func: A => F[B]): F[B]
}
#+END_SRC

#+BEGIN_QUOTE
Monad Laws

pure와 flatMap은 의도하지 않은 glichy와 side-effect 없이 자유롭게 operation을 sequence하도록 하는 법칙들을 따라야만 한다. 

/Left identity/: pure를 호출하고 func로 result를 변환하는 것은 func를 호출하는 것과 같아야 한다

pure(a).flatMap(func) == func(a)

/Right identity/: pure를 flatMap에 넘기는 것은 아무것도 하지 않은 것과 같다

m.flatMap(pure) == m

/Associativity/: 두 함수 f와 g의 flatMapping은 f에 flatMap을 하고 g에 flatMap을 하는 것과 같다

m.flatMap(f).flatMap(g) == m.flatMap(x => f(x).flatMap(g))

#+END_QUOTE
*** Exercise: Getting Func-y

** Monads in Cats
monad에게 standard Cats treatment를 주어야 할 시간이다. 일반적인 type class, instance, syntax를 볼 것이다.

*** The Monad Type Class
monad type class는 cats.Monad이다  Monad는 두 개의 서로 다른 클래스를 상속한다: flatMap method를 제공하는 FlatMap과 pure를 제공하는 Applicative이다. Applicative는 또 Functor를 상속한다. Functor는 모든 Monad에 위의 exercise에서 봤던 map method를 제공한다. Applicative에 대해서는 Chapter 6에서 논의할 것이다.

여기에 pure와 flatMap, map을 바로 사용한 예제가 있다.

#+BEGIN_SRC scala
import cats.Monad
import cats.instances.option._ // for Monad
import cats.instances.list._   // for Monad

val opt1 = Monad[Option].pure(3)
// opt1: Option[Int] = Some(3)

val opt2 = Monad[Option].flatMap(opt1)(a => Some(a + 2)) 
// opt2: Option[Int] = Some(5)

val opt3 = Monad[Option].map(opt2)(a => 100 * a)
// opt3: Option[Int] = Some(500)

val list1 = Monad[List].pure(3)
// list1: List[Int] = List(3)

val list2 = Monad[List].flatMap(List(1, 2, 3))(a => List(a, a*10))
// list2: List[Int] = List(1, 10, 2, 20, 3, 30)

val list3 = Monad[List].map(list2)(a => a + 123)
// list3: List[Int] = List(124, 133, 125, 143, 126, 153)
#+END_SRC

Monad는 Functor에 있는 method 전부를 포함해 많은 다른 method를 제공한다. 더 많은 정보는 scaladoc을 봐라

*** Default Instances
Cats는 cats.instance를 통해 standard library(Option, List, Vector 등)에 있는 모든 monad를 위한 instance를 제공한다.

#+BEGIN_SRC scala
import cats.instances.option._ // for Monad 

Monad[Option].flatMap(Option(1))(a => Option(a*2))
// res0: Option[Int] = Some(2)

import cats.instances.list._ // for Monad

Monad[List].flatMap(List(1, 2, 3))(a => List(a, a*10))
// res1: List[Int] = List(1, 10, 2, 20, 3, 30)

import cats.instances.vector._ // for Monad

Monad[Vector].flatMap(Vector(1, 2, 3))(a => Vector(a, a*10))
// res2: Vector[Int] = Vector(1, 10, 2, 20, 3, 30)
#+END_SRC

Cats는 또한 Future를 위한 Monad를 제공한다. Future 클래스에 있는 method들과 달리, monad에 있는 pure와 flatMap method들은 implicit ExecutionContext parameter들을 받을 수 없다(parameter들은 Monad trait에 있는 definition의 부분이 아니다). 이를 동작하게 하기 위해서, Cats는 Future를 위한 Monad를 소환할 때 scope 안에 ExecutionContext를 가지는 것을 요구한다:

#+BEGIN_SRC scala
import cats.instances.future._ // for Monad
import scala.concurrent._
import scala.concurrent.duration._

val fm = Monad[Future]
// <console>:37: error: could not find implicit value for parameter
instance: cats.Monad[scala.concurrent.Future] 
// val fm = Monad[Future]
// ^
#+END_SRC

ExecutionContext를 scope로 가져오는 것은 instance를 소환하기 위해 요구되는 implicit resolution을 고치도록 한다.

#+BEGIN_SRC scala
import scala.concurrent.ExecutionContext.Implicits.global

val fm = Monad[Future]
// fm: cats.Monad[scala.concurrent.Future] = cats.instances.FutureInstances$$anon$1@356fa66c
#+END_SRC

Monad instance는 pure와 flatMap의 그 다음 호출을 위해 captured된 ExecutionContext를 사용한다: 
#+BEGIN_SRC scala
val future = fm.flatMap(fm.pure(1))(x => fm.pure(x + 2))

Await.result(future, 1.second)
// res3: Int = 3
#+END_SRC

위에 추가적으로, Cats는 standard library에서 가지고 있지 않은 새로운 monad의 host를 제공한다. 이 새로운 monad들 중 몇몇은 익숙하게 될 것이다.

*** Monad Syntax
monad의 syntax는 세곳에서 온다:

- cats.syntax.flatMap은 flatMap을 위한 syntax를 제공한다;
- cats.syntax.functor는 map을 위한 syntax를 제공한다;
- cats.syntax.applicative는 pure를 위한 syntax를 제공한다;

실제로는, 종종 cats.implicits로 쉽게 모든 것을 import한다. 하지만 여기서는 명확하게 하기 위해서 individual import를 사용할 것이다.

monad의 instance를 만들기 위해서 pure를 사용할 수 있다. 종종 우리가 원하는 특정한 instance의 차이를 분명하게 보여주기 위한 type parameter를 정의할 필요가 있다.

#+BEGIN_SRC scala
import cats.instances.option._   // for Monad
import cats.instances.list._     // for Monad
import cats.syntax.applicative._ // for pure

1.pure[Option]
// res4: Option[Int] = Some(1)

1.pure[List]
// res5: List[Int] = List(1)
#+END_SRC

Option과 List같은 Scala monad들에 직접적으로 flatMap과 map method를 증명하는 것은 어렵다. 왜냐하면 flatMap과 map method들에 대한 자체적인 explicit version이 정의되어 있기 때문이다. 대신에 사용자의 선택의 monad를 wrap한 parameter의 계산을 수행하는 generic한 function을 작성할 것이다:

#+BEGIN_SRC scala
import cats.Monad
import cats.syntax.functor._ // for map
import cats.syntax.flatMap._ // for flatMap
import scala.language.higherKinds

def sumSquare[F[_]: Monad](a: F[Int], b: F[Int]): F[Int] = 
  a.flatMap(x => b.map(y => x*x + y*y))

import cats.instances.option._ // for Monad
import cats.instances.list._   // for Monad

sumSquare(Option(3), Option(4))
// res8: Option[Int] = Some(25)

sumSquare(List(1, 2, 3), List(4, 5))
// res9: List[Int] = List(17, 26, 20, 29, 25, 34)
#+END_SRC

for comprehension을 사용해서 이 코드를 다시 작성할 것이다. compiler는 flatMap과 map의 관점에서 우리의 comprehension을 재작성하고 Monad를 사용하기 위해 정확한 implicit conversion을 추가하는 것으로 "올바르게 동작할 것이다":

#+BEGIN_SRC scala
def sumSquare[F[_]: Monad](a: F[Int], b: F[Int]): F[Int] = 
  for {
    x <- a
    y <- b
  } yield x*x + y*y

sumSquare(Option(3), Option(4))
// res10: Option[Int] = Some(25)

sumSquare(List(1, 2, 3), List(4, 5))
// res11: List[Int] = List(17, 26, 20, 29, 25, 34)
#+END_SRC

Cats에 있는 monad의 일반성에 대해 알아야 할 것들은 다 알았다. 이제 Scala standard library에서 본적없는 몇가지 유용한 monad instance들을 살펴보자

** The Identity Monad
이전 섹션에서 서로 다른 monad에 추상화된 method를 작성함으로써 Cats의 flatMap과 map syntax를 증명했다:

#+BEGIN_SRC scala
import scala.language.higherKinds
import cats.Monad
import cats.syntax.functor._ // for map
import cats.syntax.flatMap._ // for flatMap

def sumSquare[F[_]: Monad](a: F[Int], b: F[Int]): F[Int] = 
  for {
    x <- a
    y <- b
  } yield x*x + y*y
#+END_SRC

이 method는 Options와 List에는 잘 동작하지만 plain value를 넘겨서 호출할 수는 없다.

#+BEGIN_SRC scala
sumSquare(3, 4)
// <console>:22: error: no type parameters for method sumSquare: (a: F [Int], b: F[Int])(implicit evidence$1: cats.Monad[F])F[Int] exist so that it can be applied to arguments (Int, Int) // --- because ---
// argument expression's type is not compatible with formal parameter type;
//found :Int
// required: ?F[Int]
// sumSquare(3, 4)
// ^
// <console>:22: error: type mismatch; // found : Int(3)
// required: F[Int]
// sumSquare(3, 4)
// ^
// <console>:22: error: type mismatch; // found : Int(4)
// required: F[Int]
// sumSquare(3, 4)
// ^
#+END_SRC

만약 monad에 있거나 혹은 전혀 monad에 없는 parameter를 가진 sumSquare를 사용한다면 매우 유용할 것이다. 이는 monadic하고 non-monadic한 code 모두를 추상화할 수 있도록 한다. 운좋게도, Cats는 gap을 줄이기 위한 Id type을 제공한다:

#+BEGIN_SRC scala
import cats.Id

sumSquare(3 : Id[Int], 4 : Id[Int])
// res2: cats.Id[Int] = 25
#+END_SRC

Id는 plain value를 사용해서 monadic method를 호출할 수 있도록 한다. 하지만, 정확한 semantic은 이해하기 어렵다. 우리는 parameter를 Id[Int]로 sumSquare로 cast하고 Id[Int]를 결과로서 다시 돌려받는다.

무슨 일이 생긴걸까? 설명을 위한 Id의 정의는 다음고 같다

#+BEGIN_SRC scala
package cats

type Id[A] = A
#+END_SRC

Id는 atomic type이 single-parameter type constructor로 변하게 하는 type alias이다. 어떤 타입의 어떤 값도 대응되는 Id로 cast할 수 있다.

#+BEGIN_SRC scala
"Dave" : Id[String]
// res3: cats.Id[String] = Dave

123 : Id[Int]
// res4: cats.Id[Int] = 123

List(1, 2, 3) : Id[List[Int]]
// res5: cats.Id[List[Int]] = List(1, 2, 3)
#+END_SRC

Cats는 Functor와 Monad를 포함해서 Id를 위한 다양한 type class의 instance를 제공한다. 이는 plain values를 넘기는 map, flatMap, pure를 호출하게 한다

#+BEGIN_SRC scala
val a = Monad[Id].pure(3)
// a: cats.Id[Int] = 3

val b = Monad[Id].flatMap(a)(_ + 1)
// b: cats.Id[Int] = 4

import cats.syntax.functor._ // for map
import cats.syntax.flatMap._ // for flatMap

for {
  x <- a
  y <- b
} yield x + y
// res6: cats.Id[Int] = 7
#+END_SRC

monadic이나 non-monadic한 code를 추상화하기 위한 능력은 매우 강력하다. 예를 들어, Future를 사용해서 production에서는 코드를 비동기적으로 수행하고 Id를 이용해서 테스트는 동기적으로 수행할 수 있다. 이는 Chapter 8에서 살펴볼 것이다.

*** Exercise: Monadic Secret Identities
** Either
또다른 유용한 monad를 살펴보자. scala standard library의 Either type이다. Scala 2.11 혹은 그 이전 버전에서, 많은 사람들은 Either를 monad라고 생각하지 않았다. 왜냐하면 map과 flatMap method를 가지고 있지 않았기 때문이다. Scala 2.12에서 Either는 right bias가 되었다.

*** Left and Right Bias
Scala 2.11에서 Either는 default map이나 flatMap method를 가지고 있지 않았다. 이는 Scala 2.11 버전에서 Either로 for comprehension을 사용하는 데 있어서는 불편했다. 당시에는 모든 generator 구문에 .right를 호출하는 부분을 넣어야만 했다.

#+BEGIN_SRC scala
val either1: Either[String, Int] = Right(10)
val either2: Either[String, Int] = Right(32)

for {
  a <- either1.right
  b <- either2.right
} yield a + b
// res0: scala.util.Either[String,Int] = Right(42)
#+END_SRC

Scala 2.12에서는 Either가 다시 설계되었다. 새로운 Either는 right side가 성공을 표현하고 그래서 map과 flatMap을 바로 지원한다. 이는 for comprehension을 더 편하게 쓸 수있게 해주었다.

#+BEGIN_SRC scala
for {
  a <- either1
  b <- either2
 } yield a + b
// res1: scala.util.Either[String,Int] = Right(42)
#+END_SRC

Cats는 cats.syntax.either를 import함으로써 Scala 2.11의 행동으로 back-port했다. 이를 통해서 모든 scala 버전에서 right-biased된 either를 사용할 수 있다. Scala 2.12에서는 이 import를 제외하든 그대로 두든 어떤 방식도 문제가 되지 않는다.

#+BEGIN_SRC scala
import cats.syntax.either._ // for map and flatMap

for {
  a <- either1
  b <- either2
} yield a + b
#+END_SRC

*** Creating Instances
Left와 Right의 instance를 직접 생성하는 것 뿐만 아니라, cats.syntax.either로부터 asLeft와 asRight extension method를 import할 수 있다:

#+BEGIN_SRC scala
import cats.syntax.either._ // for asRight

val a = 3.asRight[String]
// a: Either[String,Int] = Right(3)

val b = 4.asRight[String]
// b: Either[String,Int] = Right(4)

for {
  x <- a
  y <- b
} yield x*x + y*y
// res4: scala.util.Either[String,Int] = Right(25)
#+END_SRC

위의 코드는 두가지 이유로 실패한다:
1. compiler는 Either 대신에 Right로서 accumulator의 타입을 추론한다.
2. Right.apply로 type parameter를 정의하지 않으므로 compiler는 left parameter를 Nothing으로 간주한다.

asRight로 변환하는 것은 이러한 두가지 문제를 피할 수 있게 해준다. asRight는 Either type으로 return하고 오직 하나의 type parameter를 가지는 type을 정의할 수 있도록 한다:

#+BEGIN_SRC scala
def countPositive(nums: List[Int]) = 
  nums.foldLeft(0.asRight[String]) { (accumulator, num) =>
    if(num > 0) {
      accumulator.map(_ + 1)
    } else {
      Left("Negative. Stopping!")
    } 
  }

countPositive(List(1, 2, 3))
// res5: Either[String,Int] = Right(3)

countPositive(List(1, -2, 3))
// res6: Either[String,Int] = Left(Negative. Stopping!)
#+END_SRC

cats.syntax.either는 몇몇 유용한 extension method를 Either companion object에 추가했다. catchOnly와 catchNonFatal method는 Either instance로서 Exception을 훌륭하게 잡을 수 있다.

#+BEGIN_SRC scala
Either.catchOnly[NumberFormatException]("foo".toInt)
// res7: Either[NumberFormatException,Int] = Left(java.lang.NumberFormatException: For input string: "foo")

Either.catchNonFatal(sys.error("Badness"))
// res8: Either[Throwable,Nothing] = Left(java.lang.RuntimeException:Badness)
#+END_SRC

다른 data type으로부터 Either를 생성하기 위한 method도 있다.

#+BEGIN_SRC scala
Either.fromTry(scala.util.Try("foo".toInt))
// res9: Either[Throwable,Int] = Left(java.lang.NumberFormatException:For input string: "foo")

Either.fromOption[String, Int](None, "Badness") 
// res10: Either[String,Int] = Left(Badness)
#+END_SRC

*** Transforming Eithers
cats.syntax.either는 Either의 instance에 몇가지 더 유용한 method들을 추가한다. right side로부터 값을 추출하거나 default값을 리턴하는 orElse와 getOrElse를 사용할 수 있다.

#+BEGIN_SRC scala
import cats.syntax.either._
"Error".asLeft[Int].getOrElse(0)
// res11: Int = 0

"Error".asLeft[Int].orElse(2.asRight[String]) 
// res12: Either[String,Int] = Right(2)
#+END_SRC

ensure method는 right-hand value가 predicate를 만족하는지 아닌지를 확인할 수 있게 해준다.

#+BEGIN_SRC scala
 -1.asRight[String].ensure("Must be non-negative!")(_ > 0) 
// res13: Either[String,Int] = Left(Must be non-negative!)
#+END_SRC

recover와 recoverWith method는 Future의 namesake와 유사한 error handling을 제공한다.

#+BEGIN_SRC scala
"error".asLeft[Int].recover {
  case str: String => -1
}
// res14: Either[String,Int] = Right(-1)

"error".asLeft[Int].recoverWith {
  case str: String => Right(-1)
}
// res15: Either[String,Int] = Right(-1)
#+END_SRC

map을 complement하는 leftMap과 bimap도 있다

#+BEGIN_SRC scala
"foo".asLeft[Int].leftMap(_.reverse)
// res16: Either[String,Int] = Left(oof)

6.asRight[String].bimap(_.reverse, _ * 7)
// res17: Either[String,Int] = Right(42)

"bar".asLeft[Int].bimap(_.reverse, _ * 7)
// res18: Either[String,Int] = Left(rab)
#+END_SRC

swap method는 left와 right를 바꾸게 해준다.

#+BEGIN_SRC scala
123.asRight[String]
// res19: Either[String,Int] = Right(123)

123.asRight[String].swap
// res20: scala.util.Either[Int,String] = Left(123)
#+END_SRC

마지막으로, Cats는 conversion method의 host를 추가한다: toOption, toList, toTry, toValidated 등등이다

*** Error Handling
Either는 일반적으로 fail-fast error handling을 사용한다. 보통 때처럼 flatMap을 사용해서 sequence하게 computation할 수 있다. 만약 하나의 computation이 fail하면, 나머지 computation은 실행되지 않는다:

#+BEGIN_SRC scala
for {
  a <- 1.asRight[String]
  b <- 0.asRight[String]
  c <- if(b == 0) "DIV0".asLeft[Int]
       else (a / b).asRight[String]
} yield c * 100
// res21: scala.util.Either[String,Int] = Left(DIV0)
#+END_SRC

Either를 error handling으로 사용할 때, 에러를 표현하기 위해서 사용하고자 하는 타입이 어떤 것인지를 결정해야 한다. 이를 위해서 Throwable을 사용할 수 있다고 해보자

#+BEGIN_SRC scala
type Result[A] = Either[Throwable, A]
#+END_SRC

이는 scala.util.Try와 유사한 semantic을 제공한다. 문제는 Throwable이 극단적으로 broad type이라는 것이다. 어떤 type의 에러가 일어날 것인가에 대한 idea가 없다. 

또다른 접근은 프로그램에서 일어날 수 있는 에러를 표현하기 위해서 algebraic data type을 정의하는 것이다:

#+BEGIN_SRC scala
sealed trait LoginError extends Product with Serializable 

final case class UserNotFound(username: String) extends LoginError
final case class PasswordIncorrect(username: String) extends LoginError

case object UnexpectedError extends LoginError

case class User(username: String, password: String)

type LoginResult = Either[LoginError, User]
#+END_SRC

이러한 접근은 Throwable에서 본 문제들을 해결한다. 이러한 것은 기대되는 error type의 고정된 집합을 제공하고 우리가 기대하지 않은 다른 것들도 모두 catch한다. 어떤 pattern matching에서도 exhaustivity checking에 대한 safety를 얻을 수 있다.

#+BEGIN_SRC scala
// Choose error-handling behaviour based on type:
def handleError(error: LoginError): Unit =
  error match {
    case UserNotFound(u) =>
      println(s"User not found: $u")
    case PasswordIncorrect(u) =>
      println(s"Password incorrect: $u")
    case UnexpectedError =>
      println(s"Unexpected error")
  }

val result1: LoginResult = User("dave", "passw0rd").asRight
// result1: LoginResult = Right(User(dave,passw0rd))

val result2: LoginResult = UserNotFound("dave").asLeft // result2: LoginResult = Left(UserNotFound(dave))

result1.fold(handleError, println)
// User(dave,passw0rd)

result2.fold(handleError, println)
// User not found: dave
#+END_SRC

*** Exercise: What is Best?
** Aside: Error Handling and MonadError
*** The MonadError Type Class
*** Raising and Handling Errors
*** Instances of MonadError
*** Exercise: Abstracting
** The Eval Monad
cats.Eval은 evaluation의 서로 다른 모델을 추상화할 수 있도록 하는 monad이다. 보통 두가지 모델에 대해서 듣는다: eager와 lazy이다. Eval은 result가 memoized되는지 안되는지에 대해 더 구별할 수 있또록 한다.

*** Eager, Lazy, Memoized, Oh My!
이 용어들이 의미하는 바가 멀까?

Eager는 computation이 즉각적으로 일어나는 것이고 lazy는 computation이 접근할 때 일어나는 것이다. Memoized는 computation이 캐싱되는 것으로 처음 접근할 때에만 일어나는 것이다.

예를 들어, Scala의 val은 eager이면서 memoized이다. visible side-effect를 가진 computation을 사용하면 이를 확인해볼 수 있다. 다음 예제에서, x의 값을 계산하기 위한 코드는 접근할 때가 아니라 정의할 때 발생한다(eager). x에 접근하는 것은 code를 rerunning하지 않고 저장된 value를 가져간다.

#+BEGIN_SRC scala
val x = {
  println("Computing X")
  math.random
}
// Computing X
// x: Double = 0.32119158749503807

x // first access
// res0: Double = 0.32119158749503807

x // second access
// res1: Double = 0.32119158749503807
#+END_SRC

이와 대조적으로, def는 lazy이고 not memoized이다. y를 계산하는 code는 실제로 접근할 때까지 동작하지 않고 매 접근시마다 rerun한다.

#+BEGIN_SRC scala
def y = {
  println("Computing Y")
  math.random
}
// y: Double

y // first access
// Computing Y
// res2: Double = 0.5179245763430056

y // second access
// Computing Y
// res3: Double = 0.8657077812314633
#+END_SRC

마지막으로 lazy val은 lazy이고 memoized이다. z를 계산하기 위한 코드는 처음 접근할 때까지 실행되지 않는다. 다음 접근시에 결과는 cash되고 reuse된다.

#+BEGIN_SRC scala
lazy val z = {
  println("Computing Z")
  math.random
}
// z: Double = <lazy>

z // first access
// Computing Z
// res4: Double = 0.027165389120539563

z // second access
// res5: Double = 0.027165389120539563
#+END_SRC

*** Eval's Models of Evaluation
Eval은 세가지 subtype을 가지고 있다: Now, Later, Always. 이를 바탕으로하는 세가지 constructor method를 만들었다. 이 method들은 세가지 클래스의 instance를 만들고 Eval type을 리턴한다.

#+BEGIN_SRC scala
import cats.Eval

val now = Eval.now(math.random + 1000)
// now: cats.Eval[Double] = Now(1000.6884369117727)

val later = Eval.later(math.random + 2000)
// later: cats.Eval[Double] = cats.Later@71175ee9

val always = Eval.always(math.random + 3000)
// always: cats.Eval[Double] = cats.Always@462e2fea
#+END_SRC

value method를 사용해서 Eval의 결과를 추출할 수 있다.

#+BEGIN_SRC scala
now.value
// res6: Double = 1000.6884369117727

later.value
// res7: Double = 2000.8775276106762

always.value
// res8: Double = 3000.6943184468
#+END_SRC

Eval의 각 type은 위에 정의된 evaluation model중 하나를 사용해서 그 결과를 계산한다. Eval.now는 바로 값을 얻어낸다. semantic은 val과 유사하다 - eager이고 memoized이다:

#+BEGIN_SRC scala
val x = Eval.now {
  println("Computing X")
  math.random
}
// Computing X
// x: cats.Eval[Double] = Now(0.8724950064732552)

x.value // first access
// res9: Double = 0.8724950064732552

x.value // second access
// res10: Double = 0.8724950064732552
#+END_SRC

Eval.always는 lazy computation을 가져온다. def와 유사하다: 
#+BEGIN_SRC scala
val y = Eval.always {
  println("Computing Y")
  math.random
}
// y: cats.Eval[Double] = cats.Always@5212e1f5

y.value // first access
// Computing Y
// res11: Double = 0.8795680260041828

y.value // second access
// Computing Y
// res12: Double = 0.5640213059400854
#+END_SRC

마지막으로 Eval.later는 lazy, memoized computation을 가져온다. lazy val과 유사하다:
#+BEGIN_SRC scala
val z = Eval.later {
  println("Computing Z")
  math.random
}
// z: cats.Eval[Double] = cats.Later@33eda11

z.value // first access
// Computing Z
// res13: Double = 0.5813583535421343

z.value // second access
// res14: Double = 0.5813583535421343
#+END_SRC

*** Eval as a Monad
모든 monad들과 같이, Eval의 map과 flatMap method는 chain에 computation을 더할 수 있다. 이 경우 chain은 function의 list로서 저장된다. function들은 result를 요청하는 Eval의 value method를 호출할 때까지 실행되지 않는다:

#+BEGIN_SRC scala
val greeting = Eval.
  always { println("Step 1"); "Hello" }.
  map { str => println("Step 2"); s"$str world" }
// greeting: cats.Eval[String] = cats.Eval$$anon$8@3a67c76e

greeting.value
// Step 1
// Step 2
// res15: String = Hello world
#+END_SRC

Eval instance의 semantic은 유지되지만 mapping function은 항상 요구에 따라 lazy하기 호출된다는 것을 기억하자.

#+BEGIN_SRC scala
val ans = for {
  a <- Eval.now { println("Calculating A"); 40 }
  b <- Eval.always { println("Calculating B"); 2 }
} yield {
  println("Adding A and B") 
  a+b
}
// Calculating A
// ans: cats.Eval[Int] = cats.Eval$$anon$8@2d96144d

ans.value // first access
// Calculating B
// Adding A and B
// res16: Int = 42

ans.value // second access
// Calculating B
// Adding A and B
// res17: Int = 42
#+END_SRC

Eval은 computation의 chain을 memoize할 수 있도록 하는 memoize method를 가지고 있다. memoize를 호출할 때까지의 chain의 결과가 cache되지만 call 이후의 calculation은 기존 semantic으로 유지된다:

#+BEGIN_SRC scala
val saying = Eval.
  always { println("Step 1"); "The cat" }.
  map { str => println("Step 2"); s"$str sat on" }.
  memoize.
  map { str => println("Step 3"); s"$str the mat" }
// saying: cats.Eval[String] = cats.Eval$$anon$8@7a0389b5

saying.value // first access
// Step 1
// Step 2
// Step 3
// res18: String = The cat sat on the mat

saying.value // second access
// Step 3
// res19: String = The cat sat on the mat
#+END_SRC

*** Trampolining and Eval.defer
Eval의 한가지 유용한 속성중 하나는 Eval의 map과 flatMap method가 trampolined라는 것이다. 이는 stack frame을 소비하지 않고 임의로 map과 flatMap을 nest call할 수 있다는 것이다. 이를 "stack safety"라고 한다

예를 들어 factorial을 계산하는 다음의 함수를 살펴보자:

#+BEGIN_SRC scala
 def factorial(n: BigInt): BigInt =
  if(n == 1) n else n * factorial(n - 1)
#+END_SRC

이 method는 쉽게 stack overflow할 수 있다:

#+BEGIN_SRC scala
factorial(50000)
// java.lang.StackOverflowError
//   ...
#+END_SRC

Eval을 사용하는 method로 stack safe하게 할 수 있다.

#+BEGIN_SRC scala
def factorial(n: BigInt): Eval[BigInt] =
  if(n == 1) {
    Eval.now(n)
  } else {
    factorial(n - 1).map(_ * n)
  }

factorial(50000).value
// java.lang.StackOverflowError
//   ...
#+END_SRC

으잉? 동작하지 않는다-stack이 여전히 폭발한다! 왜냐하면 여전히 Eval의 map method가 동작하기 전에 factorial에 대한 모든 recursive call이 만들어지기 때문이다. Eval.defer를 사용해서 동작하게 할수있다. Eval.defer는 Eval의 존재하는 instance를 가지고 그 evaluation을 지연한다. defer method는 map과 flatMap같이 trampolined되므로 이미 존재하는 operation stack safe를 하기 위한 빠른 방법으로 사용할 수 있다:

#+BEGIN_SRC scala
  def factorial(n: BigInt): Eval[BigInt] =
   if(n == 1) {
     Eval.now(n)
   } else {
     Eval.defer(factorial(n - 1).map(_ * n))
   }
 factorial(50000).value
// res20: BigInt = 334732050959714483691547609407148647791277322381045480773010032199016802214436564
#+END_SRC

Eval은 매우 큰 computation과 data structure에서 작업할 때 stack safety를 강요할 수 있는 유용한 tool이다. 하지만 trampolined는 공짜가 아니라는 것을 항상 명심하자. 이는 heap에 function object의 chain을 만듬으로써 stack에 대한 소비를 피한다. 여전히 얼마나 깊게 nest computation을 할 수 있는지에 대한 제약이 존재한다. 하지만 stack보다는 heap의 size가 경계라는 것을 알아두자.

*** Exercise: Safer Folding using Eval
** The Writer Monad
cats.data.Writer는 computation으로 log를 가져오게 하는 monad이다. Writer monad는 computation에 대한 message, error, additional data를 기록하고 마지막 결과값에 대한 log를 추출하는 데 사용할 수 있다.

Writer의 한가지 일반적인 사용예는 standard imperative logging technique이 서로 다른 context에서 간섭된 message를 만들어 낼 수 있는 multi]-threaded computation에서 step의 sequence를 recording하는 것이다. computation을 위한 log를 가진 Writer는 result에 강하게 결합되는데, 그래서 mixing log 없는 concurent computation을 실행할 수 있다.

#+BEGIN_QUOTE
Cats Data Types

Writer는 cats.data package에서 볼 수 있는 첫번째 data type이다. 이 package는 유용한 semantic을 만들 수 있는 다양한 type class의 instance를 제공한다. cats.data에 대한 다른 예제들은 다음 chapter에서 살펴볼 monad transformer를 포함하고 validated type은 Chapter 6에서 만나볼 것이다.
#+END_QUOTE

*** Creating and Unpacking Writers
Writer[W, A]는 두가지 값을 가진다: type W의 log와 type A의 result이다. 다음과 같이 각 타입의 값들로부터 Writer를 생성할 수 있다.

#+BEGIN_SRC scala
import cats.data.Writer
import cats.instances.vector._ // for Monoid

Writer(Vector(
  "It was the best of times",
  "it was the worst of times"
), 1859)
// res0: cats.data.WriterT[cats.Id,scala.collection.immutable.Vector[ String],Int] = WriterT((Vector(It was the best of times, it was the worst of times),1859))
#+END_SRC

console에 나온 type은 Writer[Vector[String], Int]가 아니라 WriterT[Id, Vector[String], Int]라는 것을 확인하자. code reuse의 철학에서, Cats는 다른 type인 WriterT의 관점에서 Writer를 구현한다. WriterT는 다음 chapter에서 다룰 monad transformer라고 불리는 새로운 개념의 예제이다.

일단 세세한 부분은 무시하자. Writer는 WriterT를 위한 type alias이고 WriterT[Id, W, A]는 Writer[W, A] type이라고 읽을 수 있다:

#+BEGIN_SRC scala
type Writer[W, A] = WriterT[Id, W, A]
#+END_SRC

편의를 위해서, Cats는 log나 result만을 정의하기 위해 Writer를 생성하는 방법을 제공한다. 만약 result만 있다면, 표준 pure syntax를 사용할 수 있다. 이를 위해서 scope에 Monoid[W]를 가지고 있어야만 하고 그래서 Cats는 어떻게 empty log를 생성하는 지 알고 있다.

#+BEGIN_SRC scala
import cats.instances.vector._   // for Monoid
import cats.syntax.applicative._ // for pure

type Logged[A] = Writer[Vector[String], A]

123.pure[Logged]
// res2: Logged[Int] = WriterT((Vector(),123))
#+END_SRC

만약 log가 있고 result가 없다면 cats.syntax.writer로부터 tell syntax를 사용하는 Writer[Unit]을 생성할 수 있다:

#+BEGIN_SRC scala
import cats.syntax.writer._ // for tell

Vector("msg1", "msg2", "msg3").tell
// res3: cats.data.Writer[scala.collection.immutable.Vector[String],Unit] = WriterT((Vector(msg1, msg2, msg3),()))
#+END_SRC

만약 result와 log 둘다 있다면, Writer.apply나 cats.syntax.writer에 있는 writer syntax를 사용할 수 있다:

#+BEGIN_SRC scala
import cats.syntax.writer._ // for writer
val a = Writer(Vector("msg1", "msg2", "msg3"), 123)
// a: cats.data.WriterT[cats.Id,scala.collection.immutable.Vector[String],Int] = WriterT((Vector(msg1, msg2, msg3),123))
val b = 123.writer(Vector("msg1", "msg2", "msg3"))
// b: cats.data.Writer[scala.collection.immutable.Vector[String],Int]= WriterT((Vector(msg1, msg2, msg3),123))
#+END_SRC

value나 written을 사용해서 Writer로부터 log나 result를 추출할 수 있다:

#+BEGIN_SRC scala
val aResult: Int =
  a.value
// aResult: Int = 123

val aLog: Vector[String] =
  a.written
// aLog: Vector[String] = Vector(msg1, msg2, msg3)
#+END_SRC

run method를 사용해서 동시에 두개의 값들을 추출할 수 있다.

#+BEGIN_SRC scala
val (log, result) = b.run
// log: scala.collection.immutable.Vector[String] = Vector(msg1, msg2,msg3)
// result: Int = 123
#+END_SRC

*** Composing and Transforming Writers
Writer에 있는 log는 map이나 flatMap을 할 때 보존된다. flatMap은 source Writer의 log와 user의 sequencing function의 결과를 추가한다. 이런 이유로 Vector와 같이 효과적인 append와 concatenate operation을 가지는 log type을 사용하기 위한 좋은 예이다:

#+BEGIN_SRC scala
val writer1 = for {
  a <- 10.pure[Logged]
  _ <- Vector("a", "b", "c").tell
  b <- 32.writer(Vector("x", "y", "z"))
} yield a + b
// writer1: cats.data.WriterT[cats.Id,Vector[String],Int] = WriterT((Vector(a, b, c, x, y, z),42))

writer1.run
// res4: cats.Id[(Vector[String], Int)] = (Vector(a, b, c, x, y, z) ,42)
#+END_SRC 

map과 flatMap의 결과를 변환하는 것 뿐만 아니라, mapWritten method를 가진 Writer에 있는 log로 변환할 수 있다:

#+BEGIN_SRC scala
val writer2 = writer1.mapWritten(_.map(_.toUpperCase))
// writer2: cats.data.WriterT[cats.Id,scala.collection.immutable. Vector[String],Int] = WriterT((Vector(A, B, C, X, Y, Z),42))

writer2.run
// res5: cats.Id[(scala.collection.immutable.Vector[String], Int)] = ( Vector(A, B, C, X, Y, Z),42)
#+END_SRC

bimap이나 mapBoth를 사용해서 계속해서 log와 result를 변환할 수 있다. bimap은 두개의 function parameter를 가진다. 하나는 log를 위한 것이고 하나는 result를 위한 것이다. mapBoth는 두 개의 parameter를 받는 single function을 가진다

#+BEGIN_SRC scala
val writer3 = writer1.bimap(
  log => log.map(_.toUpperCase),
  res => res * 100
)
// writer3: cats.data.WriterT[cats.Id,scala.collection.immutable. Vector[String],Int] = WriterT((Vector(A, B, C, X, Y, Z),4200))

writer3.run
// res6: cats.Id[(scala.collection.immutable.Vector[String], Int)] = ( Vector(A, B, C, X, Y, Z),4200)

val writer4 = writer1.mapBoth { (log, res) =>
  val log2 = log.map(_ + "!")
  val res2 = res * 1000
  (log2, res2)
}
// writer4: cats.data.WriterT[cats.Id,scala.collection.immutable. Vector[String],Int] = WriterT((Vector(a!, b!, c!, x!, y!, z!) ,42000))

writer4.run
// res7: cats.Id[(scala.collection.immutable.Vector[String], Int)] = ( Vector(a!, b!, c!, x!, y!, z!),42000)
#+END_SRC

마지막으로, reset method를 가지는 log를 clear할 수 있고 log를 swap하고 swap method와 result를 만들 수 있다.

#+BEGIN_SRC scala
val writer5 = writer1.reset
// writer5: cats.data.WriterT[cats.Id,Vector[String],Int] = WriterT((Vector(),42))

writer5.run
// res8: cats.Id[(Vector[String], Int)] = (Vector(),42)

val writer6 = writer1.swap
// writer6: cats.data.WriterT[cats.Id,Int,Vector[String]] = WriterT((42,Vector(a, b, c, x, y, z)))

writer6.run
// res9: cats.Id[(Int, Vector[String])] = (42,Vector(a, b, c, x, y, z) )
#+END_SRC

*** Exercise: Show Your Working

** The Reader Monad
cats.data.Reader는 어떤 input에 따라 operation을 sequence하도록 하는 monad이다. Reader의 instance는 하나의 인자를 갖는 function으로 쌓여지고 이를 조합해서 유용한 method를 제공할 수 있도록 한다.

Reader의 일반적인 사용예는 dependency injection이다. 만약 몇몇 외부 설정에 모든 것을 의존하는 많은 operation을 가진다면, parameter로서 설정을 받고 정의된 순서로 실행되는 하나의 큰 operation을 생성하기 위해 Reader를 사용해서 모두를 chain할 수 있다.

*** Creating and Unpacking Readers
Reader.apply 생성자를 사용해서 function A => B로부터 Reader[A, B]를 생성할 수 있다.

#+BEGIN_SRC scala
import cats.data.Reader

case class Cat(name: String, favoriteFood: String)
// defined class Cat

val catName: Reader[Cat, String] =
  Reader(cat => cat.name)
// catName: cats.data.Reader[Cat,String] = Kleisli(<function1>)
#+END_SRC

Reader의 run method를 이용해서 다시 function을 추출할 수 있고 보통 때처럼 apply를 사용해서 호출할 수 있다:

#+BEGIN_SRC scala
catName.run(Cat("Garfield", "lasagne"))
// res0: cats.Id[String] = Garfield
#+END_SRC

Reader가 raw function들에 대해서 우리에게 줄 수 있는 이점은 무엇일까?

*** Composing Readers
Reader의 힘은 function composition의 다른 종류를 표현하는 map과 flatMap method로부터 온다. 보통 configuration의 같은 type을 받는 Reader를 생성하고, map과 flatMap을 가지고 조합하고, 마지막으로 config를 inject하는 run을 호출한다.

map method는 function을 통한 결과를 전달함으로써 Reader에 computation을 확장한다.

#+BEGIN_SRC scala
val greetKitty: Reader[Cat, String] =
  catName.map(name => s"Hello ${name}")

greetKitty.run(Cat("Heathcliff", "junk food")) 
// res1: cats.Id[String] = Hello Heathcliff
#+END_SRC

flatMap method는 더욱 흥미롭다. flatMap은 같은 input type에 대해 reader를 combine할 수 있도록 한다. 이를 설명하기 위해서, cat을 먹이기 위해서 greeting example을 확장해보자

#+BEGIN_SRC scala
val feedKitty: Reader[Cat, String] =
  Reader(cat => s"Have a nice bowl of ${cat.favoriteFood}")

val greetAndFeed: Reader[Cat, String] =
  for {
    greet <- greetKitty
    feed  <- feedKitty
  } yield s"$greet. $feed."

greetAndFeed(Cat("Garfield", "lasagne"))
// res3: cats.Id[String] = Hello Garfield. Have a nice bowl of lasagne.

greetAndFeed(Cat("Heathcliff", "junk food"))
// res4: cats.Id[String] = Hello Heathcliff. Have a nice bowl of junk food.
#+END_SRC

*** Exercise: Hacking on Readers
*** When to Use Readers?
Reader는 dependency injection을 하기 위한 tool을 제공한다. Reader의 instance로서 program의 단계를 작성하고, map과 flatMap으로 Reader를 chain하고, input으로 dependency를 받는 function을 build한다.

Scala에서 dependency injection을 구현하는 많은 방법들이 있다. implicit parameter와 type class를 통해서 여러개의 parameter list를 가지는 method와 같은 간단한 테크닉부터 cake pattern과 DI framework같은 복잡한 테크닉까지이다.

Reader는 다음 상황에서 아주 유용하다.

- function에 의해서 표현될 수 있는 batch program을 구축한다
- parameter들과 known parameter의 injection을 지연할 필요가 있다
- isolation에 있는 program의 part를 테스트할 수 있기를 원한다.

Reader로 프로그램의 단계들을 표현함으로써 pure function만큼 쉽게 테스트할 수 있을 뿐만 아니라 map과 flatMap combinator에 대한 접근을 할 수도 있다.

많은 dependency를 가지고 있는 더 진보적인 문제들의 경우나, 프로그램은 쉽게 pure function으로서 표현할수 없는 겨웅에는 다른 dependency injection 테크닉이 더 적절할 수도 있다.

#+BEGIN_QUOTE
Kleisli Arrows

console output으로부터 알았을 수 있는데 Reader는 Kleisli라고 불리는 다른 type의 관점에서 구현되었다. Kleisli arrow는 result type의 type constructor간에 일반화할 수 있는 Reader의 더 일반적인 형식을 제공한다. Chapter 5에서 Kleislis를 다시 살펴볼 것이다.
#+END_QUOTE

** The State Monad
cats.data.State는 computation의 부분으로서 추가적인 state를 넘길 수 있도록 한다. atomic state operation을 표현하는 State instance를 정의하고 map과 flatMap을 사용해서 이들을 함께 돌릴 수 있다. 이러한 방식으로 purely functional한 방법으로 mutation없이 mutable state를 모델링할 수 있다. 

*** Creating and Unpacking State
가장 간단한 형식으로, State[S, A]의 instance는 type S => (S, A)의 function을 나타낸다. S는 state의 type이고 A는 result의 type이다.

#+BEGIN_SRC scala
import cats.data.State

val a = State[Int, String] { state => 
  (state, s"The state is $state")
}
#+END_SRC

다시 말해서 State의 instance는 두 가지 일을 하는 function이다

- input state를 output state로 변환
- 결과를 계산

initial state를 제공하는 것으로 monad를 실행할 수 있다. State는 세가지 method를 제공한다-run, runS, runA. 이 세가지 method는 state와 result의 서로 다른 조합을 return한다. 각 method는 Eval instance를 리턴한다. Eval은 State가 stack safety를 유지하기 위해서 사용하는 것이다. 실제 result를 추출하기 위해서는 value method를 호출한다. 

#+BEGIN_SRC scala
// Get the state and the result:
val (state, result) = a.run(10).value
// state: Int = 10

// result: String = The state is 10
// Get the state, ignore the result:
val state = a.runS(10).value
// state: Int = 10

// Get the result, ignore the state:
val result = a.runA(10).value
// result: String = The state is 10
#+END_SRC

*** Composing and Transforming State
Reader와 Writer에서 보았듯이, State monad의 힘은 instance를 조합하는 데서 나온다. map과 flatMap method는 state를 하나의 instance에서 다른 instance로 thread한다. 각 개별적인 instance는 atomic state transformation을 나타내고 그 조합은 변경에 대한 완전한 sequence를 나타낸다

#+BEGIN_SRC scala
val step1 = State[Int, String] { num =>
  val ans = num + 1
  (ans, s"Result of step1: $ans")
}
// step1: cats.data.State[Int,String] = cats.data. IndexedStateT@376a962c

val step2 = State[Int, String] { num =>
  val ans = num * 2
  (ans, s"Result of step2: $ans")
}
// step2: cats.data.State[Int,String] = cats.data. IndexedStateT@6be37458

val both = for {
  a <- step1
  b <- step2
} yield (a, b)
// both: cats.data.IndexedStateT[cats.Eval,Int,Int,(String, String)] = cats.data.IndexedStateT@250c2c22

val (state, result) = both.run(20).value
// state: Int = 42
// result: (String, String) = (Result of step1: 21,Result of step2:42)
#+END_SRC

보았듯이, 이 예제에서 final state는 sequence에서 두 transformation을 적용한 결과이다. State는 비록 for comprehension에 넣지 못하더라도 step에서 step으로 옮겨갈수 있다.

State monad를 사용하는 일반적인 모델은 instance로서 computation의 각 단계를 표현하고 standard monad operator를 사용해서 단계를 조합하는 것이다. Cats는 primitive step을 위한 몇몇 간편한 구조를 제공한다:

- get은 결과로서 state를 리턴한다;
- set은 state를 update하고 unit을 리턴한다;
- pure는 state를 무시하고 제공된 결과를 리턴한다;
- inspect는 transformation function을 통해 state를 추출한다;
- modify는 update function을 사용해서 state를 업데이트한다.

#+BEGIN_SRC scala
val getDemo = State.get[Int]
// getDemo: cats.data.State[Int,Int] = cats.data.IndexedStateT@280446c5

getDemo.run(10).value
// res3: (Int, Int) = (10,10)

val setDemo = State.set[Int](30)
// setDemo: cats.data.State[Int,Unit] = cats.data.IndexedStateT@678380eb

setDemo.run(10).value
// res4: (Int, Unit) = (30,())

val pureDemo = State.pure[Int, String]("Result")
// pureDemo: cats.data.State[Int,String] = cats.data.IndexedStateT@2364f0fb

pureDemo.run(10).value
// res5: (Int, String) = (10,Result)

val inspectDemo = State.inspect[Int, String](_ + "!") // inspectDemo: cats.data.State[Int,String] = cats.data.IndexedStateT@3502f4f3

inspectDemo.run(10).value
// res6: (Int, String) = (10,10!)

val modifyDemo = State.modify[Int](_ + 1)
// modifyDemo: cats.data.State[Int,Unit] = cats.data.IndexedStateT@6acdb6ef

modifyDemo.run(10).value
// res7: (Int, Unit) = (11,())
#+END_SRC

for comprehension을 사용해서 이 building block을 조합할 수 있다. state에서 transformation만을 표현하는 중간 stage의 결과는 일반적으로 무시한다.

#+BEGIN_SRC scala
import State._

val program: State[Int, (Int, Int, Int)] = for {
  a <- get[Int]
  _ <- set[Int](a + 1)
  b <- get[Int]
  _ <- modify[Int](_ + 1)
  c <- inspect[Int, Int](_ * 1000)
} yield (a, b, c)
// program: cats.data.State[Int,(Int, Int, Int)] = cats.data.IndexedStateT@3b51107e

val (state, result) = program.run(1).value
// state: Int = 3
// result: (Int, Int, Int) = (1,2,3000)
#+END_SRC 

*** Exercise: Post-Order Calculator
** Defining Custom Monads
세가지 method의 implementation을 제공하는 custom type을 위한 Monad를 정의할 수 있다: ~flatMap~, ~pure~, 그리고 ~tailRecM~ 이라고 불리는 아직 보지 못한 method말이다. 예제로서 ~Option~ 을 위한 ~Monad~ 의 구현은 다음과 같다: 

#+BEGIN_SRC scala
import cats.Monad
import scala.annotation.tailrec

val optionMonad = new Monad[Option] {
  def flatMap[A, B](opt: Option[A])
      (fn: A => Option[B]): Option[B] =
    opt flatMap fn

  def pure[A](opt: A): Option[A] =
    Some(opt)

  @tailrec
  def tailRecM[A, B](a: A)
      (fn: A => Option[Either[A, B]]): Option[B] =
    fn(a) match {
      case None           => None
      case Some(Left(a1)) => tailRecM(a1)(fn)
      case Some(Right(b)) => Some(b)
  } 
}
#+END_SRC

~tailRecM~ method는 ~flatMap~ 에 대한 nested call로 인해 소비되는 stack space의 양을 제한하기 위해서 Cats에서 사용되는 optimisation이다. 이 technique은 PureScript 개발자인 Phil Freeman에 의한 2015 paper에 있는 것이다. method는 ~fn~ 의 결과가 ~Right~ 를 리턴할 때까지 스스로를 재귀적으로 호출해야만 한다. 

만약 tailRecM tail-recursive를 만들수 있다면, Cats는 큰 list를 fold하는 것처럼 recursive situation에서 stack safety를 보장할 수 있다. 만약 tailRecM tail-recursive를 만들 수 없다면, Cats는 이러한 보장을 할 수 없고 극단적인 use case는 ~StackOverflowError~ 를 일으킬 수 있다. Cats에 built-in된 모든 monad는 ~tailRecM~ 의 tail-recursive 구현을 가진다. 비록 custom monad를 위한 것을 작성하는 것이 도전이긴 하지만 말이다.

*** Exercise: Branching out Further with Monads
** Summary


* Monad Transaformers
Monad는 브리또와 같다. 한번 맛을 보면 스스로 그것을 계속해서 다시 가져오는 방법을 찾게 될 것이다. 이 부분에 이슈가 없는 것은 아니다. 브리또는 허리를 부풀게 할수 있는 것처럼, monad도 nested for-comprehension을 통해 code base를 부풀게 할 수 있다.

데이터베이스와 통신하는 것을 상상해보자. 사용자 record를 찾고자 한다고 하자. 사용자는 있을 수도 있고, 없을 수도 있으므로 Option[User]를 리턴한다. 데이터베이스와의 통신은 다양한 이유로 실패할 수 있다.(네트워크 이슈, 인증 문제 등) 그래서 이 결과는 Either[Error, Option[User]]의 마지막 값을 주는 Either로 쌓일수 있다.

이 값을 사용하기 위해서는 flatMap call을 nest해야만 한다(혹은 for-comprehension과 동일하다)

#+BEGIN_SRC scala
def lookupUserName(id: Long): Either[Error, Option[String]] = for {
    optUser <- lookupUser(id)
  } yield {
    for { user <- optUser } yield user.name
  }
#+END_SRC

이는 빠르게 매우 지루해졌다.

** Exercise: Composing Monads
한가지 질문이 떠오른다. 두 개의 임의의 monad가 주어졌다고 하자, 이 두개를 하나의 monad로 만들수 있을까? 그 말인 즉슨 monad가 compose될 수 있을까? 다음과 같이 코드를 작성할수 있다. 하지만 문제가 있는 코드다

#+BEGIN_SRC scala
import cats.Monad
import cats.syntax.applicative._ // for pure
import cats.syntax.flatMap._     // for flatMap
import scala.language.higherKinds

// Hypothetical example. This won't actually compile:
def compose[M1[_]: Monad, M2[_]: Monad] = {
  type Composed[A] = M1[M2[A]]

  new Monad[Composed] {
    def pure[A](a: A): Composed[A] =
      a.pure[M2].pure[M1]

    def flatMap[A, B](fa: Composed[A])
        (f: A => Composed[B]): Composed[B] =
      // Problem! How do we write flatMap?
      ??? 
  }
}
#+END_SRC

M1과 M2에 대해서 무언가 알지 못하면 ~flatMap~ 의 일반적인 정의를 작성하는 것은 불가능하다. 하지만, 만약 우리가 하나 혹은 다른 monad에 대해서 무언가를 안다면, 이 코드를 완성할 수 있다. 예를 들어, 만약 M2를 Option으로 고칠 수 있다면 ~flatMap~ 의 정의를 할 수 있다.

#+BEGIN_SRC scala
def flatMap[A, B](fa: Composed[A])
    (f: A => Composed[B]): Composed[B] =
  fa.flatMap(_.fold(None.pure[M])(f))
#+END_SRC

위의 정의는 ~None~ 의 사용을 가능하게 했다는 것을 기억하자(~None~ 은 일반적인 ~Monad~ interface에서 볼 수 없는 Option-specific 개념이다) ~Option~ 과 다른 monad들을 조합하기 위해서는 이러한 extra detail이 필요하다. 이와 유사하게 monadeㅡㄹ을 위한 ~flatMap~ method들을 조합하는 것을 도와주는 다른 monad들에 대한 것들이 있다. 이러한 것이 monad transformer의 기반이 되는 아이디어이다. Cats는 다양한 monad를 위한 transformer들을 정의하고 있고, 각각의 transformer들은 다른 monad들을 compose하기 위해서 필요한 extra knowledge를 제공해야 한다. 몇가지 예제를 살펴보자 

** A Transformative Example
Cats는 많은 monad들을 위한 transformer를 제공한다. 각각의 transformer는 T의 suffix를 가진 이름을 가지고 있다. ~EitherT~ 는 Either를 다른 모나드와 compose해주고, ~OptionT~ 는 Option과 compose해주는 것과 같다

다음은 List[Option[A]]를 하나의 monad로 transform하기 위해서 ~OptionT~ 를 사용해서 ~List~ 와 ~Option~ 을 compose하는 예제이다. ~OptionT[List, A]~ 를 편의상 ~ListOption[A]~ 로 alias했다.  

#+BEGIN_SRC scala
import cats.data.OptionT

type ListOption[A] = OptionT[List, A]
#+END_SRC

ListOption을 안에서 밖으로 어떻게 꺼내는지를 볼 필요가 있다. 외부 monad의 타입인 List를 inner monad를 위한 transformer인 OptionT에 파라미터로 넘긴다.

OptionT constructor나 더 편리하게는 pure를 사용해서 ListOption의 instance를 생성할 수 있다

#+BEGIN_SRC scala
import cats.Monad
import cats.instances.list._     // for Monad
import cats.syntax.applicative._ // for pure

val result1: ListOption[Int] = OptionT(List(Option(10))) // result1: ListOption[Int] = OptionT(List(Some(10)))

val result2: ListOption[Int] = 32.pure[ListOption] // result2: ListOption[Int] = OptionT(List(Some(32)))
#+END_SRC

~map~ 과 ~flatMap~ method는 ~List~ 와 ~Option~ 을 하나의 operation으로 만들어주는 method에 대응되는 method들을 combine한다

#+BEGIN_SRC scala
result1.flatMap { (x: Int) =>
  result2.map { (y: Int) =>
    x+y 
  }
}
#+END_SRC

이것이 모든 monad transformer의 기본이다. combined ~map~ 과 ~flatMap~ 은 recursive하게 computation의 각 단계마다 값을 unpack과 repack하지 않고 component monad를 사용할 수 있게 해준다. API를 좀 더 깊게 살펴보자

#+BEGIN_QUOTE
import의 복잡성



#+END_QUOTE

** Monad Transformers in Cats
각 monad transformer는 cats.data에 정의된 data type이고, 이는 새로운 monad를 만들기 위해 monad의 stack을 쌓을 수 있도록 한다. Monad type class를 통해서 우리가 만든 monad를 사용할 수 있다. monad transformer를 이해하기 위해서 우리가 다루어야 하는 주요 개념은 다음과 같다:

- 사용가능한 transformer class들;
- transformer를 이용해서 monad들의 stack을 어떻게 만드는지;
- monad stack의 instance들을 어떻게 구축하는지;
- wrapped monad에 접근하기 위해서 stack을 어떻게 pull apart하는지; 

*** The Monad Transformer Classes 
convention에 따라, Cats에서 monad Foo는 FooT라고 불리는 transformer class를 가지게 될 것이다. 사실, Cats의 많은 monad들은 Id monad를 가진 monad transformer와 combine되는 것으로 정의된다. 더 자세하게 보면, 사용가능한 instance의 몇몇은 다음과 같다

- Option을 위한 cats.data.OptionT
- Either를 위한 cats.data.EitherT
- Reader를 위한 cats.data.ReaderT
- Writer를 위한 cats.data.WriterT
- State를 위한 cats.data.StateT
- Id monad를 위한 cats.data.IdT

#+BEGIN_QUOTE
Klesli Arrows

Section 4.8에서 Reader monad는 "kleisli arrow"라고 불리는 더 일반적인 개념의 specialisation이라고 했었다. Cats에서는 cats.data.Kleisli로 표현된다.

이제 Kleisli와 ReaderT는 사실 똑같은 것이라는 것을 알 수 있다. ReaderT는 Kleisli로 type alias되어 있다.
#+END_QUOTE

*** Building Monad Stacks
이 모든 monad transformer는 같은 convention을 따른다. transformer 자체는 stack에서 inner monad를 표현하지만, 첫번째 type parameter는 outer monad를 정의한다. 남은 type parameter들은 대응되는 monad를 형성하기 위해서 사용된 type들이다.

예를 들어, ListOPtion type은 OptionT[List, A]로 alias되었다. 하지만 result는 List[Option[A]]이다. 다시 말해 안에서부터 밖으로 monad stack을 구축한다.

#+BEGIN_SRC scala
type ListOption[A] = OptionT[List, A]
#+END_SRC

많은 monad들과 모든 transformer들은 최소한 두개의 type parameter를 가지고, 그래서 종종 중간 단계를 위한 type alias들을 정의해야만 한다.

예를 들어, 

*** Constructing and Unpacking Instances
*** Default Instances
*** Usage Patterns
** Exercise: Monads: Transform and Roll Out
** Summary

* Semigroupal and Applicative
** Semigroupal
*** Joining Two Contexts
*** Joining Three or MOre Contexts
** Apply Syntax
*** Fancy Funtors and Apply Syntax
** Semigroupal Applied to Different Types
*** Semigroupal Applied to Monads 
**** Exercise: The Product of Monads 
** Validated
*** Creating Instances of Validated
*** Combining Instances of Validated
*** Methods of Validated
*** Exercise: Form Validation
** Apply and Applicative
*** The Hierarchy of Sequencing Type Classes
** Summary

* Foldable and Traverse
** Foldable 
*** Folds and Folding
*** Exericse: Reflecting on Folds
*** Exericse: Scaf-fold-ing Other Methods
*** Foldable in Cats
**** Folding Right
**** Folding with Monoids
**** Syntax for Foldable
** Traverse
*** Traversing with Futures
*** Traversing with Applicatives
**** Exercise: Traversing with Vectors
**** Exercise: Traversing with Options
**** Exercise: Traversing with Validated
*** Traverse in Cats
** Summary




